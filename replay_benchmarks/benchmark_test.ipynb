{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing core directory\n",
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from replay_benchmarks.utils.conf import load_config, seed_everything\n",
    "from replay_benchmarks import TrainRunner, InferRunner\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from rs_datasets import MovieLens, Netflix\n",
    "\n",
    "from replay.data import (\n",
    "    FeatureHint,\n",
    "    FeatureInfo,\n",
    "    FeatureSchema,\n",
    "    FeatureSource,\n",
    "    FeatureType,\n",
    "    Dataset,\n",
    ")\n",
    "from replay.preprocessing.filters import MinCountFilter, NumInteractionsFilter\n",
    "from replay.splitters import TimeSplitter\n",
    "from replay.utils import DataFrameLike\n",
    "from replay.data.nn import (\n",
    "    SequenceTokenizer,\n",
    "    SequentialDataset,\n",
    "    TensorFeatureSource,\n",
    "    TensorSchema,\n",
    "    TensorFeatureInfo,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from replay.models.nn.sequential.sasrec import (\n",
    "    SasRecTrainingDataset,\n",
    "    SasRecValidationDataset,\n",
    "    SasRecPredictionDataset,\n",
    ")\n",
    "from replay.models.nn.sequential.bert4rec import (\n",
    "    Bert4RecTrainingDataset,\n",
    "    Bert4RecValidationDataset,\n",
    "    Bert4RecPredictionDataset,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule\n",
    "\n",
    "from replay_benchmarks.base_runner import BaseRunner\n",
    "from replay.metrics import OfflineMetrics, Recall, Precision, MAP, NDCG, HitRate, MRR\n",
    "from replay.metrics.torch_metrics_builder import metrics_to_df\n",
    "from replay.models.nn.sequential import SasRec, Bert4Rec\n",
    "from replay.models.nn.optimizer_utils import FatOptimizerFactory\n",
    "from replay.models.nn.sequential.callbacks import ValidationMetricsCallback\n",
    "from replay.models.nn.sequential.postprocessors import RemoveSeenItems\n",
    "from replay.models.nn.sequential.sasrec import (\n",
    "    SasRecTrainingDataset,\n",
    "    SasRecValidationDataset,\n",
    "    SasRecPredictionDataset,\n",
    ")\n",
    "from replay.models.nn.sequential.bert4rec import (\n",
    "    Bert4RecTrainingDataset,\n",
    "    Bert4RecValidationDataset,\n",
    "    Bert4RecPredictionDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = \"./replay_benchmarks/configs\"\n",
    "base_config_path = os.path.join(config_dir, \"config.yaml\")\n",
    "config = load_config(base_config_path, config_dir)\n",
    "\n",
    "seed_everything(config[\"env\"][\"SEED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config\n",
    "model_name = config[\"model\"][\"name\"]\n",
    "dataset_name = config[\"dataset\"][\"name\"]\n",
    "dataset_cfg = config[\"dataset\"]\n",
    "model_cfg = config[\"model\"][\"params\"]\n",
    "mode = config[\"mode\"][\"name\"]\n",
    "item_column = dataset_cfg[\"feature_schema\"][\"item_column\"]\n",
    "user_column = dataset_cfg[\"feature_schema\"][\"query_column\"]\n",
    "timestamp_column = dataset_cfg[\"feature_schema\"][\"timestamp_column\"]\n",
    "tokenizer = None\n",
    "interactions = None\n",
    "user_features = None\n",
    "item_features = None\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = config[\"env\"][\"CUDA_DEVICE_ORDER\"]\n",
    "os.environ[\"OMP_NUM_THREADS\"] = config[\"env\"][\"OMP_NUM_THREADS\"]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config[\"env\"][\"CUDA_VISIBLE_DEVICES\"]\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"recsysaccelerate\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"6363e91b656fea576c39e4f55dcc1d00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<replay.data.nn.schema.TensorSchema at 0x7f27889f47d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = model_cfg[\"training_params\"][\"embedding_dim\"]\n",
    "item_feature_name = \"item_id_seq\"\n",
    "\n",
    "tensor_schema =  TensorSchema(\n",
    "    TensorFeatureInfo(\n",
    "        name=item_feature_name,\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_sources=[\n",
    "            TensorFeatureSource(\n",
    "                FeatureSource.INTERACTIONS,\n",
    "                item_column,\n",
    "            )\n",
    "        ],\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "        embedding_dim=embedding_dim,\n",
    "    )\n",
    ")\n",
    "\n",
    "tensor_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_MAPPINGS = {\n",
    "    \"zvuk\": {\"kaggle\": \"alexxl/zvuk-dataset\", \"file\": \"zvuk-interactions.parquet\"},\n",
    "    \"megamarket\": {\"kaggle\": \"alexxl/megamarket\", \"file\": \"megamarket.parquet\"},\n",
    "}\n",
    "SUPPORTED_RS_DATASETS = [\"movielens\", \"netflix\"]\n",
    "\n",
    "def _download_dataset(\n",
    "    data_path: str, dataset_name: str, interactions_file: str\n",
    "):\n",
    "    \"\"\"Download dataset from Kaggle or rs_datasets.\"\"\"\n",
    "    if dataset_name in DATASET_MAPPINGS:\n",
    "        _download_kaggle_dataset(data_path, dataset_name, interactions_file)\n",
    "    elif any(ds in dataset_name for ds in SUPPORTED_RS_DATASETS):\n",
    "        _download_rs_dataset(data_path, dataset_name, interactions_file)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "def _download_kaggle_dataset(\n",
    "    data_path: str, dataset_name: str, interactions_file: str\n",
    ") -> None:\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    \"\"\"Download dataset from Kaggle.\"\"\"\n",
    "    kaggle_info = DATASET_MAPPINGS[dataset_name]\n",
    "    kaggle_dataset = kaggle_info[\"kaggle\"]\n",
    "    raw_data_file = os.path.join(data_path, kaggle_info[\"file\"])\n",
    "\n",
    "    os.environ.setdefault(\"KAGGLE_USERNAME\", \"recsysaccelerate\")\n",
    "    os.environ.setdefault(\"KAGGLE_KEY\", \"6363e91b656fea576c39e4f55dcc1d00\")\n",
    "\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    api.dataset_download_files(kaggle_dataset, path=data_path, unzip=True)\n",
    "    logging.info(f\"Dataset downloaded and extracted to {data_path}\")\n",
    "\n",
    "    interactions = pd.read_parquet(raw_data_file)\n",
    "    interactions[timestamp_column] = interactions[\n",
    "        timestamp_column\n",
    "    ].astype(\"int64\")\n",
    "    if dataset_name == \"megamarket\":\n",
    "        interactions = interactions[interactions.event == 2] # take only purchase\n",
    "    interactions.to_parquet(interactions_file)\n",
    "\n",
    "def _download_rs_dataset(\n",
    "    data_path: str, dataset_name: str, interactions_file: str\n",
    ") -> None:\n",
    "    \"\"\"Download dataset from rs_datasets.\"\"\"\n",
    "    if \"movielens\" in dataset_name:\n",
    "        version = dataset_name.split(\"_\")[1]\n",
    "        movielens = MovieLens(version=version, path=data_path)\n",
    "        interactions = movielens.ratings\n",
    "        interactions = interactions[interactions[dataset_cfg[\"feature_schema\"][\"rating_column\"]] > dataset_cfg[\"preprocess\"][\"min_rating\"]]\n",
    "    elif dataset_name == \"netflix\":\n",
    "        netflix = Netflix(path=data_path)\n",
    "        interactions = pd.concat([netflix.train, netflix.test]).fillna(5).reset_index(drop=True)\n",
    "        interactions = interactions[interactions[dataset_cfg[\"feature_schema\"][\"rating_column\"]] > dataset_cfg[\"preprocess\"][\"min_rating\"]]\n",
    "        interactions = interactions.sort_values(by=[user_column, timestamp_column])\n",
    "        interactions[timestamp_column] += interactions.groupby([user_column, timestamp_column]).cumcount()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "    interactions[timestamp_column] = interactions[\n",
    "        timestamp_column\n",
    "    ].astype(\"int64\")\n",
    "    interactions.to_parquet(interactions_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "3        1     3408       4  978300275\n",
       "4        1     2355       5  978824291\n",
       "6        1     1287       5  978302039\n",
       "7        1     2804       5  978300719"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = dataset_cfg[\"name\"]\n",
    "data_path = dataset_cfg[\"path\"]\n",
    "interactions_file = os.path.join(data_path, \"interactions.parquet\")\n",
    "\n",
    "if not os.path.exists(interactions_file):\n",
    "    _download_dataset(data_path, dataset_name, interactions_file)\n",
    "\n",
    "interactions = pd.read_parquet(interactions_file)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(interactions.groupby(user_column).size().min(), interactions.groupby(item_column).size().min())\n",
    "\n",
    "interactions = MinCountFilter(\n",
    "    num_entries=dataset_cfg[\"preprocess\"][\"min_users_per_item\"],\n",
    "    groupby_column=item_column,\n",
    ").transform(interactions)\n",
    "\n",
    "interactions = MinCountFilter(\n",
    "    num_entries=dataset_cfg[\"preprocess\"][\"min_items_per_user\"],\n",
    "    groupby_column=user_column,\n",
    ").transform(interactions)\n",
    "\n",
    "\n",
    "interactions.groupby(user_column).size().min(), interactions.groupby(item_column).size().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cfg[\"preprocess\"][\"global_split_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_id'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of seq_len in validation:\n",
      "count    448.000000\n",
      "mean      24.837054\n",
      "std       49.389768\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        6.500000\n",
      "75%       26.000000\n",
      "max      656.000000\n",
      "Name: item_id, dtype: float64.\n",
      "Distribution of seq_len in test:\n",
      "count    999.000000\n",
      "mean      43.796797\n",
      "std       59.198925\n",
      "min        1.000000\n",
      "25%        7.000000\n",
      "50%       23.000000\n",
      "75%       57.000000\n",
      "max      585.000000\n",
      "Name: item_id, dtype: float64.\n"
     ]
    }
   ],
   "source": [
    "splitter = TimeSplitter(\n",
    "    time_threshold=dataset_cfg[\"preprocess\"][\"global_split_ratio\"],\n",
    "    drop_cold_users=True,\n",
    "    drop_cold_items=True,\n",
    "    item_column=item_column,\n",
    "    query_column=user_column,\n",
    "    timestamp_column=timestamp_column,\n",
    ")\n",
    "\n",
    "# train_events, validation_events, validation_gt, test_events, test_gt = (\n",
    "#     _split_data(splitter, interactions)\n",
    "# )\n",
    "\n",
    "test_events, test_gt = splitter.split(interactions)\n",
    "validation_events, validation_gt = splitter.split(test_events)\n",
    "train_events = validation_events\n",
    "\n",
    "test_gt = test_gt[test_gt[item_column].isin(train_events[item_column])]\n",
    "test_gt = test_gt[test_gt[user_column].isin(train_events[user_column])]\n",
    "\n",
    "\n",
    "# Limit number of gt events in val and test only if max_num_test_interactions is not null\n",
    "max_test_interactions = dataset_cfg[\"preprocess\"][\"max_num_test_interactions\"]\n",
    "print(f\"Distribution of seq_len in validation:\\n{validation_gt.groupby(user_column)[item_column].agg('count').describe()}.\")\n",
    "print(f\"Distribution of seq_len in test:\\n{test_gt.groupby(user_column)[item_column].agg('count').describe()}.\")\n",
    "if max_test_interactions is not None:\n",
    "    \n",
    "    validation_gt = NumInteractionsFilter(\n",
    "        num_interactions=max_test_interactions,\n",
    "        first=True,\n",
    "        query_column=user_column,\n",
    "        item_column=item_column,\n",
    "        timestamp_column=timestamp_column,\n",
    "    ).transform(validation_gt)\n",
    "    print(f\"Distribution of seq_len in validation  after filtering:\\n{validation_gt.groupby(user_column)[item_column].agg('count').describe()}.\")\n",
    "\n",
    "    test_gt = NumInteractionsFilter(\n",
    "        num_interactions=max_test_interactions,\n",
    "        first=True,\n",
    "        query_column=user_column,\n",
    "        item_column=item_column,\n",
    "        timestamp_column=timestamp_column,\n",
    "    ).transform(test_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140725</th>\n",
       "      <td>904</td>\n",
       "      <td>2348</td>\n",
       "      <td>4</td>\n",
       "      <td>977939424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140721</th>\n",
       "      <td>904</td>\n",
       "      <td>858</td>\n",
       "      <td>4</td>\n",
       "      <td>977939543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140660</th>\n",
       "      <td>904</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>977939543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140668</th>\n",
       "      <td>904</td>\n",
       "      <td>2866</td>\n",
       "      <td>5</td>\n",
       "      <td>977939573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140696</th>\n",
       "      <td>904</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>977939573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating  timestamp\n",
       "140725      904     2348       4  977939424\n",
       "140721      904      858       4  977939543\n",
       "140660      904      260       5  977939543\n",
       "140668      904     2866       5  977939573\n",
       "140696      904     1193       4  977939573"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events['timestamp'].max() <= validation_events['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('timestamp', 'item_id', 'user_id')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_column, item_column, user_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_splitting(events, gt, name=''):\n",
    "    if events[timestamp_column].max() > gt[timestamp_column].min():\n",
    "        print(\"Problem with time points in\", name)\n",
    "    if len(set(gt[user_column].unique().tolist()) - set(events[user_column].unique().tolist())) > 0:\n",
    "        print(\"Problem with cold users in\", name)\n",
    "    if len(set(gt[item_column].unique().tolist()) - set(events[item_column].unique().tolist())) > 0:\n",
    "        print(\"Problem with cold items in\", name)\n",
    "\n",
    "\n",
    "test_splitting(train_events, test_gt, \"train events, test gt\")\n",
    "test_splitting(train_events, validation_gt, \"train events, valid gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1, 2, 3])  - set({1, 2, 3, 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_feature_schema(is_ground_truth: bool) -> FeatureSchema:\n",
    "    \"\"\"Prepare the feature schema based on whether ground truth is needed.\"\"\"\n",
    "    base_features = FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=user_column,\n",
    "                feature_hint=FeatureHint.QUERY_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=item_column,\n",
    "                feature_hint=FeatureHint.ITEM_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    if is_ground_truth:\n",
    "        return base_features\n",
    "\n",
    "    return base_features + FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=timestamp_column,\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "                feature_hint=FeatureHint.TIMESTAMP,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "feature_schema = prepare_feature_schema(is_ground_truth=False)\n",
    "ground_truth_schema = prepare_feature_schema(is_ground_truth=True)\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=train_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=validation_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt_dataset = Dataset(\n",
    "    feature_schema=ground_truth_schema,\n",
    "    interactions=validation_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=test_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt_dataset = Dataset(\n",
    "    feature_schema=ground_truth_schema,\n",
    "    interactions=test_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SequenceTokenizer(\n",
    "    tensor_schema, allow_collect_to_master=True, handle_unknown_rule=\"drop\"\n",
    ")\n",
    "tokenizer.fit(train_dataset)\n",
    "\n",
    "seq_train_dataset = tokenizer.transform(train_dataset)\n",
    "# seq_validation_dataset, seq_validation_gt = _prepare_sequential_validation(\n",
    "#     validation_dataset, validation_gt\n",
    "# )\n",
    "\n",
    "seq_validation_dataset = tokenizer.transform(validation_dataset)\n",
    "seq_validation_gt = tokenizer.transform(\n",
    "    validation_gt_dataset, [tensor_schema.item_id_feature_name]\n",
    ")\n",
    "\n",
    "seq_validation_dataset, seq_validation_gt = SequentialDataset.keep_common_query_ids(\n",
    "            seq_validation_dataset, seq_validation_gt\n",
    ")\n",
    "\n",
    "\n",
    "test_query_ids = test_gt_dataset.query_ids\n",
    "test_query_ids_np = tokenizer.query_id_encoder.transform(test_query_ids)[\n",
    "    user_column\n",
    "].values\n",
    "seq_test_dataset = tokenizer.transform(test_dataset).filter_by_query_id(\n",
    "    test_query_ids_np\n",
    ")\n",
    "# seq_test_dataset = self._prepare_sequential_test(test_dataset, test_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mapping = {\n",
    "    \"sasrec\": (\n",
    "        SasRecTrainingDataset,\n",
    "        SasRecValidationDataset,\n",
    "        SasRecPredictionDataset,\n",
    "    ),\n",
    "    \"bert4rec\": (\n",
    "        Bert4RecTrainingDataset,\n",
    "        Bert4RecValidationDataset,\n",
    "        Bert4RecPredictionDataset,\n",
    "    ),\n",
    "}\n",
    "\n",
    "if model_name.lower() in dataset_mapping:\n",
    "    TrainingDataset, ValidationDataset, PredictionDataset = dataset_mapping[\n",
    "        model_name.lower()\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Unsupported model type for dataloaders: {model_name}\"\n",
    "    )\n",
    "\n",
    "common_params = {\n",
    "    \"batch_size\": model_cfg[\"training_params\"][\"batch_size\"],\n",
    "    \"num_workers\": model_cfg[\"training_params\"][\"num_workers\"],\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=TrainingDataset(\n",
    "        seq_train_dataset,\n",
    "        max_sequence_length=model_cfg[\"model_params\"][\"max_seq_len\"],\n",
    "    ),\n",
    "    shuffle=True,\n",
    "    **common_params,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=ValidationDataset(\n",
    "        seq_validation_dataset,\n",
    "        seq_validation_gt,\n",
    "        seq_train_dataset,\n",
    "        max_sequence_length=model_cfg[\"model_params\"][\"max_seq_len\"],\n",
    "    ),\n",
    "    **common_params,\n",
    ")\n",
    "prediction_dataloader = DataLoader(\n",
    "    dataset=PredictionDataset(\n",
    "        seq_test_dataset,\n",
    "        max_sequence_length=model_cfg[\"model_params\"][\"max_seq_len\"],\n",
    "    ),\n",
    "    **common_params,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"tensor_schema\": tensor_schema,\n",
    "    \"optimizer_factory\": FatOptimizerFactory(\n",
    "        learning_rate=model_cfg[\"training_params\"][\"learning_rate\"]\n",
    "    ),\n",
    "}\n",
    "model_config.update(model_cfg[\"model_params\"])\n",
    "\n",
    "if model_name.lower() == \"sasrec\":\n",
    "    model = SasRec(**model_config)\n",
    "elif model_name.lower() == \"bert4rec\":\n",
    "    model = Bert4Rec(**model_config)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model type: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 300, 200, 0.5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._model.num_blocks, model._model.num_heads, model._model.hidden_size, model._model.max_len, model._model.dropout,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA L40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /root/RePlay-Accelerated/replay_benchmarks/artifacts/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | _model | SasRecModel      | 2.1 M \n",
      "1 | _loss  | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.333     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1abdbf900c4a1ea07bad82328ede65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.011161  0.002856  0.002105  0.003579\n",
      "ndcg    0.011161  0.008803  0.009175  0.006939\n",
      "recall  0.000099  0.003524  0.007127  0.001563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472a8fc5d5c84b688d6f7d1188a525b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdad0072d144486b7e2867a7204526c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 11: 'recall@10' reached 0.02311 (best 0.02311), saving model to '/root/RePlay-Accelerated/replay_benchmarks/artifacts/checkpoints/epoch=0-step=11.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.080357  0.036929  0.025865  0.053575\n",
      "ndcg    0.080357  0.070369  0.061387  0.080768\n",
      "recall  0.003216  0.023113  0.031875  0.014469\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089cc8b0a7a74ce386b7d12a1da251cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 22: 'recall@10' reached 0.02639 (best 0.02639), saving model to '/root/RePlay-Accelerated/replay_benchmarks/artifacts/checkpoints/epoch=1-step=22.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.098214  0.038816  0.029808  0.052094\n",
      "ndcg    0.098214  0.075509  0.071305  0.081600\n",
      "recall  0.003642  0.026391  0.041841  0.018992\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc92de49cfc04f82a7ff24386d1914d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 33: 'recall@10' reached 0.03409 (best 0.03409), saving model to '/root/RePlay-Accelerated/replay_benchmarks/artifacts/checkpoints/epoch=2-step=33.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.104911  0.047535  0.037365  0.060964\n",
      "ndcg    0.104911  0.088558  0.083550  0.094753\n",
      "recall  0.006163  0.034094  0.052836  0.021975\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7f107dce07452085280e16dbf8084f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 44: 'recall@10' reached 0.03502 (best 0.03502), saving model to '/root/RePlay-Accelerated/replay_benchmarks/artifacts/checkpoints/epoch=3-step=44-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.107143  0.047636  0.037331  0.062310\n",
      "ndcg    0.107143  0.089641  0.085274  0.095612\n",
      "recall  0.005453  0.035018  0.057148  0.021860\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99578e174b214542bdac6213a2e91e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 55: 'recall@10' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.080357  0.044953  0.034910  0.059148\n",
      "ndcg    0.080357  0.085084  0.081622  0.092615\n",
      "recall  0.002798  0.032290  0.053254  0.019643\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a82f08ce39b4b88a76e8736b26a2e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 66: 'recall@10' reached 0.03518 (best 0.03518), saving model to '/root/RePlay-Accelerated/replay_benchmarks/artifacts/checkpoints/epoch=5-step=66-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.080357  0.045338  0.035814  0.059472\n",
      "ndcg    0.080357  0.086204  0.084212  0.093205\n",
      "recall  0.002798  0.035179  0.059607  0.018023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=config[\"paths\"][\"checkpoint_dir\"],\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "# validation_metrics_callback = ValidationMetricsCallback(\n",
    "#     metrics=config[\"metrics\"][\"types\"],\n",
    "#     ks=config[\"metrics\"][\"ks\"],\n",
    "#     item_count=train_dataset.item_count,\n",
    "#     postprocessors=[RemoveSeenItems(seq_validation_dataset)],\n",
    "# )\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(seq_validation_dataset)]\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=model_cfg[\"training_params\"][\"max_epochs\"],\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
