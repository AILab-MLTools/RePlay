{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение моделей RePlay\n",
    "\n",
    "### Датасеты\n",
    "Сравним результаты моделей RePlay на популярных датасетах __MovieLens 1m__, __MovieLens 20m__ (explicit feedback) и __last_fm__ и __steam__ (implicit feedback). \n",
    "\n",
    "### Предобработка данных: \n",
    "Для датасетов MovieLens будем считать оценку >= 3 положительным взаимодействием для моделей, использующих факт взаимодействия/информацию о положительном/отрицательном взаимодействии.\n",
    "\n",
    "### Разбиение данных:\n",
    "Выберем в test последний (или случайный, если время оценки не определено) оцененный объект для 40% пользователей с удалением холодных объектов и пользователей из теста. \n",
    "\n",
    "### Predict:\n",
    "Предскажем по 10 объектов для пользователей test.\n",
    "\n",
    "### Метрики\n",
    "Оценим качество моделелей в метриках __ndcg, hit rage, map__ для k = 1, 5, 10 и разнообразие рекомендаций в метрике __coverage__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:01:45.639135Z",
     "start_time": "2020-02-10T16:01:45.612577Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from pyspark.sql import functions as sf, types as st\n",
    "\n",
    "from replay.session_handler import State, logger_with_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:09.227179Z",
     "start_time": "2020-02-10T15:59:06.427348Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1435c1e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = State().session\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import ERROR\n",
    "State().logger.setLevel(ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "K_list_metrics = [1, 5, 10]\n",
    "BUDGET=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Подготовка данных <a name='data-preparator'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:42.041251Z",
     "start_time": "2020-02-10T15:59:09.230636Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .boolean { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .integer { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .string  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109\n",
       "2        1      914       3  978301968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "users\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  occupation zip_code\n",
       "0        1      F    1          10    48067\n",
       "1        2      M   56          16    70072\n",
       "2        3      M   25          15    55117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                    title                        genres\n",
       "0        1         Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2           Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3  Grumpier Old Men (1995)                Comedy|Romance"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rs_datasets import MovieLens\n",
    "\n",
    "data = MovieLens(\"1m\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from replay.data_preparator import DataPreparator\n",
    "\n",
    "log_ml_1 = DataPreparator().transform(\n",
    "    data=data.ratings,\n",
    "    columns_names={\n",
    "        \"user_id\": \"user_id\",\n",
    "        \"item_id\": \"item_id\",\n",
    "        \"relevance\": \"rating\",\n",
    "        \"timestamp\": \"timestamp\"\n",
    "    }\n",
    ")\n",
    "log_ml_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = DataPreparator().transform(\n",
    "    data=data.users,\n",
    "    columns_names={\n",
    "        \"user_id\": \"user_id\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836478, 163731)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# рассматриваем как положительный фидбэк только оценки >= 3\n",
    "only_positives_log = log_ml_1.filter(sf.col('relevance') >= 3)\n",
    "only_negatives_log = log_ml_1.filter(sf.col('relevance') < 3).withColumn('relevance', sf.lit(0.))\n",
    "only_positives_log.count(), only_negatives_log.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:50.986401Z",
     "start_time": "2020-02-10T15:59:42.042998Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834063, 2411)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from replay.splitters import UserSplitter\n",
    "\n",
    "train_spl = UserSplitter(\n",
    "    drop_cold_items=True,\n",
    "    drop_cold_users=True,\n",
    "    item_test_size=1,\n",
    "    user_test_size=0.4,\n",
    "    seed=1234,\n",
    "    shuffle=False\n",
    ")\n",
    "full_train, test = train_spl.split(only_positives_log)\n",
    "(full_train.count(), test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:50.986401Z",
     "start_time": "2020-02-10T15:59:42.042998Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2413, 2411)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_spl = UserSplitter(\n",
    "    drop_cold_items=True,\n",
    "    drop_cold_users=True,\n",
    "    item_test_size=1,\n",
    "    user_test_size=0.4,\n",
    "    seed=1234,\n",
    "    shuffle=False\n",
    ")\n",
    "train, val = val_spl.split(full_train)\n",
    "(val.count(), test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995379"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilson_train=train.withColumn('relevance', sf.lit(1)).union(only_negatives_log)\n",
    "wilson_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Оценка качества моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.experiment import Experiment\n",
    "from replay.metrics import MAP, NDCG, HitRate, Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Experiment(test, {MAP(): K, NDCG(): K, HitRate(): K_list_metrics, Coverage(log_ml_1): K})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Неперсонализированные рекомендации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.models import PopRec, RandomRec, Wilson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelParams = namedtuple('ModelParams', ['name', 'model', 'search_space'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_personalized_models = [\n",
    "    ModelParams('poprec', PopRec(), None),\n",
    "    ModelParams('wilson', Wilson(), None),\n",
    "    ModelParams('random_rec', RandomRec(), 'default'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_add_res(name, model, experiment):\n",
    "    start_time=time.time()\n",
    "    if name=='wilson':\n",
    "        pred=model.fit_predict(log=wilson_train, \n",
    "                          k=K, \n",
    "                          users=test.select('user_id').distinct())\n",
    "    else:\n",
    "        pred=model.fit_predict(log=full_train, \n",
    "                          k=K, \n",
    "                          users=test.select('user_id').distinct())\n",
    "    pred.count()\n",
    "    experiment.results.loc[name, 'time'] = time.time() - start_time    \n",
    "    experiment.add_result(name, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(models, experiment):\n",
    "    for model_params in models:\n",
    "#         start_time\n",
    "        model_params.model.logger.error(msg='{} started'.format(model_params.name))\n",
    "        if model_params.search_space is not None:\n",
    "            model_params.model.logger.error(msg='{} optimization started'.format(model_params.name))\n",
    "            if model_params.search_space == 'default':\n",
    "                best_params = model_params.model.optimize(train, val, k=K, budget=BUDGET)\n",
    "            else:\n",
    "                best_params = model_params.model.optimize(train, val, param_grid=model_params.search_space, k=K, budget=BUDGET)\n",
    "            model_params.model.set_params(**best_params)\n",
    "            experiment.results.loc[model_params.name, 'params'] = best_params.__repr__()\n",
    "            \n",
    "        logger.debug(msg='{} fit_predict started'.format(model_params.name))\n",
    "        fit_predict_add_res(model_params.name, model_params.model, experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-Feb-21 14:33:09, replay, ERROR: poprec started\n",
      "ERROR:replay:poprec started\n",
      "10-Feb-21 14:33:42, replay, ERROR: wilson started\n",
      "ERROR:replay:wilson started\n",
      "10-Feb-21 14:34:27, replay, ERROR: random_rec started\n",
      "ERROR:replay:random_rec started\n",
      "10-Feb-21 14:34:27, replay, ERROR: random_rec optimization started\n",
      "ERROR:replay:random_rec optimization started\n",
      "\u001b[32m[I 2021-02-10 14:34:27,693]\u001b[0m A new study created in memory with name: no-name-9b7b2125-9907-452e-8ed7-0263a9cc496d\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:34:41,749]\u001b[0m Trial 0 finished with value: 0.0044797038668894255 and parameters: {'distribution': 'popular_based', 'alpha': 84.34489319355359}. Best is trial 0 with value: 0.0044797038668894255.\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:34:53,196]\u001b[0m Trial 1 finished with value: 0.005647592070192276 and parameters: {'distribution': 'popular_based', 'alpha': 20.819693294265026}. Best is trial 1 with value: 0.005647592070192276.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_pipeline(non_personalized_models, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverage@10</th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>HitRate@10</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>time</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>poprec</th>\n",
       "      <td>0.037777</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>0.048528</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>9.686460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wilson</th>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>15.368459</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_rec</th>\n",
       "      <td>0.825418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>13.011448</td>\n",
       "      <td>{'distribution': 'popular_based', 'alpha': 20....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coverage@10  HitRate@1  HitRate@5  HitRate@10    MAP@10   NDCG@10  \\\n",
       "poprec         0.037777   0.007466   0.026960    0.048528  0.016832  0.024126   \n",
       "wilson         0.018079   0.001659   0.009125    0.015761  0.004658  0.007210   \n",
       "random_rec     0.825418   0.000000   0.003733    0.009540  0.001904  0.003650   \n",
       "\n",
       "                 time                                             params  \n",
       "poprec       9.686460                                                NaN  \n",
       "wilson      15.368459                                                NaN  \n",
       "random_rec  13.011448  {'distribution': 'popular_based', 'alpha': 20....  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.results.sort_values('NDCG@10', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Классические коллаборативные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.models import KNN, ALSWrap, SLIM, ADMMSLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborative_models = [\n",
    "    ModelParams('knn', KNN(), 'default'),\n",
    "    ModelParams('als', ALSWrap(), 'default'),\n",
    "    ModelParams('slim', SLIM(), 'default'),\n",
    "    ModelParams('admm_slim', ADMMSLIM(), 'default'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-Feb-21 14:38:21, replay, ERROR: knn started\n",
      "ERROR:replay:knn started\n",
      "10-Feb-21 14:38:21, replay, ERROR: knn optimization started\n",
      "ERROR:replay:knn optimization started\n",
      "\u001b[32m[I 2021-02-10 14:38:21,704]\u001b[0m A new study created in memory with name: no-name-36f5be2e-b3c8-43be-855a-5000eb9eb976\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:40:32,782]\u001b[0m Trial 0 finished with value: 0.03179201817682271 and parameters: {'num_neighbours': 97, 'shrink': 51}. Best is trial 0 with value: 0.03179201817682271.\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:42:47,469]\u001b[0m Trial 1 finished with value: 0.031876034354646324 and parameters: {'num_neighbours': 43, 'shrink': 80}. Best is trial 1 with value: 0.031876034354646324.\u001b[0m\n",
      "10-Feb-21 14:45:43, replay, ERROR: als started\n",
      "ERROR:replay:als started\n",
      "10-Feb-21 14:45:43, replay, ERROR: als optimization started\n",
      "ERROR:replay:als optimization started\n",
      "\u001b[32m[I 2021-02-10 14:45:43,900]\u001b[0m A new study created in memory with name: no-name-fdf12257-2a20-44de-b15e-b5c475cc6ff6\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:46:21,653]\u001b[0m Trial 0 finished with value: 0.04163442428542982 and parameters: {'rank': 14}. Best is trial 0 with value: 0.04163442428542982.\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:50:43,335]\u001b[0m Trial 1 finished with value: 0.05758040271968534 and parameters: {'rank': 223}. Best is trial 1 with value: 0.05758040271968534.\u001b[0m\n",
      "10-Feb-21 14:56:36, replay, ERROR: slim started\n",
      "ERROR:replay:slim started\n",
      "10-Feb-21 14:56:36, replay, ERROR: slim optimization started\n",
      "ERROR:replay:slim optimization started\n",
      "\u001b[32m[I 2021-02-10 14:56:36,416]\u001b[0m A new study created in memory with name: no-name-c7b1f771-8b18-4ae0-9022-cc290e40f66b\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:57:56,068]\u001b[0m Trial 0 finished with value: 0.054329753860364975 and parameters: {'beta': 0.27813030335133976, 'lambda_': 2.1531470615965845e-06}. Best is trial 0 with value: 0.054329753860364975.\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 14:59:18,127]\u001b[0m Trial 1 finished with value: 0.012653498591686489 and parameters: {'beta': 3.1755845380086247e-06, 'lambda_': 0.00020749989556510803}. Best is trial 0 with value: 0.054329753860364975.\u001b[0m\n",
      "10-Feb-21 15:02:23, replay, ERROR: admm_slim started\n",
      "ERROR:replay:admm_slim started\n",
      "10-Feb-21 15:02:23, replay, ERROR: admm_slim optimization started\n",
      "ERROR:replay:admm_slim optimization started\n",
      "\u001b[32m[I 2021-02-10 15:02:23,082]\u001b[0m A new study created in memory with name: no-name-25ac961f-c05f-402c-8898-b046e07a1430\u001b[0m\n",
      "\u001b[32m[I 2021-02-10 15:04:43,518]\u001b[0m Trial 0 finished with value: 0.05689818693124893 and parameters: {'lambda_1': 5.726383675641074e-05, 'lambda_2': 2.2051963947668467}. Best is trial 0 with value: 0.05689818693124893.\u001b[0m\n",
      "\u001b[33m[W 2021-02-10 15:05:59,948]\u001b[0m Trial 1 failed because of the following error: Py4JJavaError('An error occurred while calling o53597.collectToPython.\\n', JavaObject id=o53598)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/optuna/_optimize.py\", line 198, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/a18785698/Documents/code_dir/replay/replay/optuna_objective.py\", line 47, in __call__\n",
      "    return self.objective_calculator(trial=trial, **self.kwargs)\n",
      "  File \"/Users/a18785698/Documents/code_dir/replay/replay/optuna_objective.py\", line 154, in scenario_objective_calculator\n",
      "    criterion_value = criterion(recs, split_data.test, k)\n",
      "  File \"/Users/a18785698/Documents/code_dir/replay/replay/metrics/base_metric.py\", line 43, in __call__\n",
      "    return self.mean(recommendations, ground_truth, k)\n",
      "  File \"/Users/a18785698/Documents/code_dir/replay/replay/metrics/base_metric.py\", line 161, in mean\n",
      "    .select(\"total_metric\", \"k\")\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/sql/dataframe.py\", line 596, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 131, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o53597.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 13972.0 failed 1 times, most recent failure: Lost task 2.0 in stage 13972.0 (TID 26505, 192.168.1.70, executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3445)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor170.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: java.lang.OutOfMemoryError: Java heap space\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o53597.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 13972.0 failed 1 times, most recent failure: Lost task 2.0 in stage 13972.0 (TID 26505, 192.168.1.70, executor driver): java.lang.OutOfMemoryError: Java heap space\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3448)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3445)\n\tat jdk.internal.reflect.GeneratedMethodAccessor170.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d85435dc218b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollaborative_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-6079fdf32ce4>\u001b[0m in \u001b[0;36mfull_pipeline\u001b[0;34m(models, experiment)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{} optimization started'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBUDGET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBUDGET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/replay/replay/models/base_rec.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, train, test, user_features, item_features, param_grid, criterion, k, budget)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         )\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         )\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             )\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/replay/replay/optuna_objective.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mзначение\u001b[0m \u001b[0mкритерия\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mкоторый\u001b[0m \u001b[0mоптимизируется\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/replay/replay/optuna_objective.py\u001b[0m in \u001b[0;36mscenario_objective_calculator\u001b[0;34m(trial, search_space, split_data, recommender, criterion, k)\u001b[0m\n\u001b[1;32m    152\u001b[0m     ).cache()\n\u001b[1;32m    153\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-- Подсчет метрики в оптимизации\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mcriterion_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s=%.2f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcriterion_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/replay/replay/metrics/base_metric.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, recommendations, ground_truth, k)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mзначение\u001b[0m \u001b[0mметрики\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     def conf_interval(\n",
      "\u001b[0;32m~/Documents/code_dir/replay/replay/metrics/base_metric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, recommendations, ground_truth, k)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cum_agg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_metric\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_metric\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         )\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \"\"\"\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o53597.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 13972.0 failed 1 times, most recent failure: Lost task 2.0 in stage 13972.0 (TID 26505, 192.168.1.70, executor driver): java.lang.OutOfMemoryError: Java heap space\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3448)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3445)\n\tat jdk.internal.reflect.GeneratedMethodAccessor170.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 50612)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a18785698/.pyenv/versions/3.7.6/lib/python3.7/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/a18785698/.pyenv/versions/3.7.6/lib/python3.7/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/a18785698/.pyenv/versions/3.7.6/lib/python3.7/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/a18785698/.pyenv/versions/3.7.6/lib/python3.7/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(collaborative_models, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обучение модели \n",
    "\n",
    "#### SLIM\n",
    "Один из простых, но эффективных алгоритмов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.models import SLIM\n",
    "\n",
    "slim = SLIM(lambda_=0.01, beta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-Feb-21 01:04:18, replay, DEBUG: Начало обучения SLIM\n",
      "DEBUG:replay:Начало обучения SLIM\n",
      "04-Feb-21 01:04:18, replay, DEBUG: Предварительная стадия обучения (pre-fit)\n",
      "DEBUG:replay:Предварительная стадия обучения (pre-fit)\n",
      "04-Feb-21 01:04:19, replay, DEBUG: Основная стадия обучения (fit)\n",
      "DEBUG:replay:Основная стадия обучения (fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 120 ms, total: 2.27 s\n",
      "Wall time: 7.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "slim.fit(log=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-Feb-21 01:04:25, replay, DEBUG: Начало предикта SLIM\n",
      "DEBUG:replay:Начало предикта SLIM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 831 ms, sys: 133 ms, total: 964 ms\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recs = slim.predict(\n",
    "    k=K,\n",
    "    users=test.select('user_id').distinct(),\n",
    "    items=test.select('item_id').distinct(),\n",
    "    log=train,\n",
    "    filter_seen_items=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Оценка качества и сравнение результатов моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке реализованы различные метрики качества рекомендательных систем, встречающихся в литературе.\n",
    "Их можно использовать напрямую, либо запоминать результаты с помощью класса `Experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:07:28.942205Z",
     "start_time": "2020-02-10T16:07:26.281475Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from replay.metrics import HitRate, NDCG, MAP\n",
    "from replay.experiment import Experiment\n",
    "\n",
    "metrics = Experiment(test, {NDCG(): K,\n",
    "                            MAP() : K,\n",
    "                            HitRate(): [1, int(K/2), K]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 ms, sys: 49.2 ms, total: 156 ms\n",
      "Wall time: 55.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>HitRate@10</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.18002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HitRate@1  HitRate@5  HitRate@10    MAP@10  NDCG@10\n",
       "SLIM      0.072      0.218       0.328  0.135137  0.18002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "metrics.add_result(\"SLIM\", recs)\n",
    "metrics.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Конвертация в pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.842803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018</td>\n",
       "      <td>1221</td>\n",
       "      <td>0.790892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.714433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id item_id  relevance\n",
       "0    1018    1200   0.842803\n",
       "1    1018    1221   0.790892\n",
       "2    1018      10   0.714433"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_pd = recs.toPandas()\n",
    "recs_pd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Примеры использования других моделей RePlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS\n",
    "Библиотека также содержит классические алгоритмы рекомендаций, например, матричную факторизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from replay.models import ALSWrap\n",
    "\n",
    "als = ALSWrap(rank=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-Feb-21 01:05:28, replay, DEBUG: Начало обучения ALSWrap\n",
      "DEBUG:replay:Начало обучения ALSWrap\n",
      "04-Feb-21 01:05:28, replay, DEBUG: Предварительная стадия обучения (pre-fit)\n",
      "DEBUG:replay:Предварительная стадия обучения (pre-fit)\n",
      "04-Feb-21 01:05:30, replay, DEBUG: Основная стадия обучения (fit)\n",
      "DEBUG:replay:Основная стадия обучения (fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 326 ms, sys: 49.2 ms, total: 375 ms\n",
      "Wall time: 49.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "als.fit(log=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-Feb-21 01:06:18, replay, DEBUG: Начало предикта ALSWrap\n",
      "DEBUG:replay:Начало предикта ALSWrap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 846 ms, sys: 145 ms, total: 991 ms\n",
      "Wall time: 5.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs = als.predict(\n",
    "    k=K,\n",
    "    users=test.select('user_id').distinct(),\n",
    "    items=test.select('item_id').distinct(),\n",
    "    log=train,\n",
    "    filter_seen_items=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.5 ms, sys: 25.4 ms, total: 115 ms\n",
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>HitRate@10</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.18002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALS</th>\n",
       "      <td>0.064</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.149850</td>\n",
       "      <td>0.20300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HitRate@1  HitRate@5  HitRate@10    MAP@10  NDCG@10\n",
       "SLIM      0.072      0.218       0.328  0.135137  0.18002\n",
       "ALS       0.064      0.258       0.376  0.149850  0.20300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "metrics.add_result(\"ALS\", recs)\n",
    "metrics.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultVAE \n",
    "Пример использования DL в рекомендациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:51.024567Z",
     "start_time": "2020-02-10T15:59:50.988776Z"
    }
   },
   "outputs": [],
   "source": [
    "from replay.models import MultVAE\n",
    "\n",
    "multvae = MultVAE(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:06:06.306042Z",
     "start_time": "2020-02-10T16:01:52.107394Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-Feb-21 01:06:34, replay, DEBUG: Начало обучения MultVAE\n",
      "DEBUG:replay:Начало обучения MultVAE\n",
      "04-Feb-21 01:06:34, replay, DEBUG: Предварительная стадия обучения (pre-fit)\n",
      "DEBUG:replay:Предварительная стадия обучения (pre-fit)\n",
      "04-Feb-21 01:06:35, replay, DEBUG: Основная стадия обучения (fit)\n",
      "DEBUG:replay:Основная стадия обучения (fit)\n",
      "04-Feb-21 01:06:36, replay, DEBUG: Составление батча:\n",
      "DEBUG:replay:Составление батча:\n",
      "04-Feb-21 01:06:38, replay, DEBUG: Обучение модели\n",
      "DEBUG:replay:Обучение модели\n",
      "04-Feb-21 01:06:39, replay, DEBUG: Epoch[1] current loss: 1352.15152\n",
      "DEBUG:replay:Epoch[1] current loss: 1352.15152\n",
      "04-Feb-21 01:06:39, replay, DEBUG: Epoch[1] validation average loss: 1480.69092\n",
      "DEBUG:replay:Epoch[1] validation average loss: 1480.69092\n",
      "04-Feb-21 01:06:41, replay, DEBUG: Epoch[2] current loss: 1251.65600\n",
      "DEBUG:replay:Epoch[2] current loss: 1251.65600\n",
      "04-Feb-21 01:06:41, replay, DEBUG: Epoch[2] validation average loss: 1472.20325\n",
      "DEBUG:replay:Epoch[2] validation average loss: 1472.20325\n",
      "04-Feb-21 01:06:42, replay, DEBUG: Epoch[3] current loss: 1297.42473\n",
      "DEBUG:replay:Epoch[3] current loss: 1297.42473\n",
      "04-Feb-21 01:06:42, replay, DEBUG: Epoch[3] validation average loss: 1451.88965\n",
      "DEBUG:replay:Epoch[3] validation average loss: 1451.88965\n",
      "04-Feb-21 01:06:43, replay, DEBUG: Epoch[4] current loss: 1262.59088\n",
      "DEBUG:replay:Epoch[4] current loss: 1262.59088\n",
      "04-Feb-21 01:06:43, replay, DEBUG: Epoch[4] validation average loss: 1405.45825\n",
      "DEBUG:replay:Epoch[4] validation average loss: 1405.45825\n",
      "04-Feb-21 01:06:44, replay, DEBUG: Epoch[5] current loss: 1254.43925\n",
      "DEBUG:replay:Epoch[5] current loss: 1254.43925\n",
      "04-Feb-21 01:06:44, replay, DEBUG: Epoch[5] validation average loss: 1399.48120\n",
      "DEBUG:replay:Epoch[5] validation average loss: 1399.48120\n",
      "04-Feb-21 01:06:46, replay, DEBUG: Epoch[6] current loss: 1242.85766\n",
      "DEBUG:replay:Epoch[6] current loss: 1242.85766\n",
      "04-Feb-21 01:06:46, replay, DEBUG: Epoch[6] validation average loss: 1423.22119\n",
      "DEBUG:replay:Epoch[6] validation average loss: 1423.22119\n",
      "04-Feb-21 01:06:47, replay, DEBUG: Epoch[7] current loss: 1235.40132\n",
      "DEBUG:replay:Epoch[7] current loss: 1235.40132\n",
      "04-Feb-21 01:06:47, replay, DEBUG: Epoch[7] validation average loss: 1417.11096\n",
      "DEBUG:replay:Epoch[7] validation average loss: 1417.11096\n",
      "04-Feb-21 01:06:48, replay, DEBUG: Epoch[8] current loss: 1232.52290\n",
      "DEBUG:replay:Epoch[8] current loss: 1232.52290\n",
      "04-Feb-21 01:06:49, replay, DEBUG: Epoch[8] validation average loss: 1420.08984\n",
      "DEBUG:replay:Epoch[8] validation average loss: 1420.08984\n",
      "04-Feb-21 01:06:50, replay, DEBUG: Epoch[9] current loss: 1231.77562\n",
      "DEBUG:replay:Epoch[9] current loss: 1231.77562\n",
      "04-Feb-21 01:06:50, replay, DEBUG: Epoch[9] validation average loss: 1433.75330\n",
      "DEBUG:replay:Epoch[9] validation average loss: 1433.75330\n",
      "04-Feb-21 01:06:51, replay, DEBUG: Epoch[10] current loss: 1219.01995\n",
      "DEBUG:replay:Epoch[10] current loss: 1219.01995\n",
      "04-Feb-21 01:06:51, replay, DEBUG: Epoch[10] validation average loss: 1422.93909\n",
      "DEBUG:replay:Epoch[10] validation average loss: 1422.93909\n",
      "04-Feb-21 01:06:52, replay, DEBUG: Epoch[11] current loss: 1227.08349\n",
      "DEBUG:replay:Epoch[11] current loss: 1227.08349\n",
      "04-Feb-21 01:06:52, replay, DEBUG: Epoch[11] validation average loss: 1413.89160\n",
      "DEBUG:replay:Epoch[11] validation average loss: 1413.89160\n",
      "04-Feb-21 01:06:54, replay, DEBUG: Epoch[12] current loss: 1226.46922\n",
      "DEBUG:replay:Epoch[12] current loss: 1226.46922\n",
      "04-Feb-21 01:06:54, replay, DEBUG: Epoch[12] validation average loss: 1418.64355\n",
      "DEBUG:replay:Epoch[12] validation average loss: 1418.64355\n",
      "04-Feb-21 01:06:55, replay, DEBUG: Epoch[13] current loss: 1216.48557\n",
      "DEBUG:replay:Epoch[13] current loss: 1216.48557\n",
      "04-Feb-21 01:06:55, replay, DEBUG: Epoch[13] validation average loss: 1421.17200\n",
      "DEBUG:replay:Epoch[13] validation average loss: 1421.17200\n",
      "04-Feb-21 01:06:56, replay, DEBUG: Epoch[14] current loss: 1220.89788\n",
      "DEBUG:replay:Epoch[14] current loss: 1220.89788\n",
      "04-Feb-21 01:06:56, replay, DEBUG: Epoch[14] validation average loss: 1415.08667\n",
      "DEBUG:replay:Epoch[14] validation average loss: 1415.08667\n",
      "04-Feb-21 01:06:58, replay, DEBUG: Epoch[15] current loss: 1221.30462\n",
      "DEBUG:replay:Epoch[15] current loss: 1221.30462\n",
      "INFO:ignite.handlers.early_stopping.EarlyStopping:EarlyStopping: Stop training\n",
      "04-Feb-21 01:06:58, replay, DEBUG: Epoch[15] validation average loss: 1409.00818\n",
      "DEBUG:replay:Epoch[15] validation average loss: 1409.00818\n",
      "04-Feb-21 01:06:58, replay, DEBUG: -- Загрузка модели из файла\n",
      "DEBUG:replay:-- Загрузка модели из файла\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 5.52 s, total: 1min 21s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multvae.fit(log=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:07:26.278582Z",
     "start_time": "2020-02-10T16:06:39.118983Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-Feb-21 01:06:58, replay, DEBUG: Начало предикта MultVAE\n",
      "DEBUG:replay:Начало предикта MultVAE\n",
      "04-Feb-21 01:07:02, replay, DEBUG: Предсказание модели\n",
      "DEBUG:replay:Предсказание модели\n",
      "/Users/a18785698/Documents/code_dir/base_replay_376/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 178 ms, total: 1.4 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recs = multvae.predict(\n",
    "    k=10,\n",
    "    users=test.select('user_id').distinct(),\n",
    "    items=test.select('item_id').distinct(),\n",
    "    log=train,\n",
    "    filter_seen_items=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 95.7 ms, sys: 85 ms, total: 181 ms\n",
      "Wall time: 29.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>HitRate@10</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.180020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALS</th>\n",
       "      <td>0.064</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.149850</td>\n",
       "      <td>0.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultVAE</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.027518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HitRate@1  HitRate@5  HitRate@10    MAP@10   NDCG@10\n",
       "SLIM         0.072      0.218       0.328  0.135137  0.180020\n",
       "ALS          0.064      0.258       0.376  0.149850  0.203000\n",
       "MultVAE      0.012      0.030       0.050  0.020785  0.027518"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "metrics.add_result(\"MultVAE\", recs)\n",
    "metrics.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Сравнение результатов различных моделей\n",
    "С помощью experiment можно сравнить качество моделей, построенных с использованием различных инструментов.\n",
    "Предположим, мы хотим сравнить модели RePlay с некой \"внешней\" моделью. Для этого нужно:\n",
    "* 5.1. Экспортировать обучающую выборку (в pandas/numpy/csv)\n",
    "* 5.2. Обучить модель и получить рекомендации для всех пользователей в виде csv/pandas-датафрейма\n",
    "* 5.3. Считать рекомендации с помощью DataPreparator\n",
    "* 5.4. Посчитать метрики в experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Экспортируем train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train.toPandas().to_csv(\"train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id,item_id,relevance,timestamp\n",
      "1,1029,5.0,2001-01-01 01:36:45\n",
      "1,2294,4.0,2001-01-07 02:38:11\n",
      "1,3114,4.0,2001-01-01 01:36:14\n",
      "1,783,4.0,2001-01-07 02:38:11\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Обучаем модель и получаем рекомендации в формате `id пользователя - id объекта - relevance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что это произошло, и у нас есть рекомендации в виде csv-файла. Ниже в качестве пример используем рекомендации, полученные одной из моделей, с рандомными релевантностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "recs.withColumn('relevance', rand(seed=123)).toPandas().to_csv(\"recs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Теперь нужно прочитать рекомендации в формате, поддерживаемом библиотекой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "recs = DataPreparator().transform(\n",
    "    path=\"recs.csv\",\n",
    "    columns_names={\n",
    "        \"user_id\": \"user_id\",\n",
    "        \"item_id\": \"item_id\",\n",
    "        \"relevance\": \"relevance\"\n",
    "    },\n",
    "    header=True,\n",
    "    format_type=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Сравним качество внешней модели с предыдущими результатами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>HitRate@10</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALS</th>\n",
       "      <td>0.064</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.149850</td>\n",
       "      <td>0.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.180020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultVAE</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.027518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_model</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>0.020113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          HitRate@1  HitRate@5  HitRate@10    MAP@10   NDCG@10\n",
       "ALS           0.064      0.258       0.376  0.149850  0.203000\n",
       "SLIM          0.072      0.218       0.328  0.135137  0.180020\n",
       "MultVAE       0.012      0.030       0.050  0.020785  0.027518\n",
       "my_model      0.002      0.022       0.050  0.011313  0.020113"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.add_result(\"my_model\", recs)\n",
    "metrics.results.sort_values(\"NDCG@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "movielens_nmf.ipynb",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "null"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
