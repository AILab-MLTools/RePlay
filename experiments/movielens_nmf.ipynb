{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование доступных моделей\n",
    "Данный ноутбук показывает базовый порядок работы с библиотекой.\n",
    "- загрузка датасета\n",
    "- деление на трейн и тест\n",
    "- обучение модели\n",
    "- сравнение с бейзлайном\n",
    "\n",
    "Документацию можно собрать из папки `docs` командой `make html`. Она создаст папку `_build` с документацией -- `sponge-bob-magic/docs/_build/html/index.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:41:18.283429Z",
     "start_time": "2020-03-02T08:41:17.826654Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:41:18.298695Z",
     "start_time": "2020-03-02T08:41:18.285234Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "parent_dir = os.path.split(os.getcwd())[0]\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая архитектура библиотеки - ЛД 3.0, поэтому используем Spark.\n",
    "Для отладки моделей (не на кластере) создаём локальную сессию.\n",
    "\n",
    "Объект `State` позволяет использовать одну и ту же сессию Spark в разных объектах.\n",
    "Если сессия уже инициализированна, то её нужно передать при инициализации `State`. Модули библиотеки, которым необходимо использовать спарк-сессию, например для конвертации из пандас в спарк, будут искать сессию именно в `State`.\n",
    "\n",
    "По умолчанию создастся дефолтная сессия. Простой способ получить сессию с заданным количеством выделенной памяти -- функция `get_spark_session` модуля `session_handler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:41:24.292990Z",
     "start_time": "2020-03-02T08:41:19.138291Z"
    },
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x116846b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sponge_bob_magic.session_handler import State\n",
    "\n",
    "spark = State().session\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных <a name='data-preparator'></a>\n",
    "Библиотека содержит утилиты для скачивания и парсинга популярных датасетов для рекомендаций.\n",
    "Если датасет не найден в заданной директории, он будет автоматически скачан и обработан.\n",
    "\n",
    "Данные датасета доступны в виде `pandas.DataFrame` атрибутов объекта.\n",
    "Посмотреть доступные данные можно с помощью метода `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:41:29.070830Z",
     "start_time": "2020-03-02T08:41:24.294721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  relevance  timestamp\n",
       "0        1     1193          5  978300760\n",
       "1        1      661          3  978302109\n",
       "2        1      914          3  978301968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "users\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  occupation zip_code\n",
       "0        1      F    1          10    48067\n",
       "1        2      M   56          16    70072\n",
       "2        3      M   25          15    55117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                    title                        genres\n",
       "0        1         Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2           Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3  Grumpier Old Men (1995)                Comedy|Romance"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sponge_bob_magic.datasets import MovieLens\n",
    "\n",
    "data = MovieLens(\"1m\")\n",
    "data.ratings.to_csv(\"data.csv\", index=False)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутренний формат данных в либе -- спарк датафрейм. Сплиттеры умеют втоматически конвертировать пандас датафреймы, но модели сейчас ожидают именно спарк, причем с заданными обязательными колонками: `user_id, item_id, timestamp, relevance, context`. \n",
    "\n",
    "Получить данные в нужном формате можно с помощью `DataPreparator.transform_log`, который создаст нужные колонки, если их нет. Сейчас он умеет только читать с диска, поэтому на предыдущем шаге мы сохранили данные в виде csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:41:37.714352Z",
     "start_time": "2020-03-02T08:41:29.072836Z"
    }
   },
   "outputs": [],
   "source": [
    "from sponge_bob_magic.data_preparator import DataPreparator\n",
    "\n",
    "log = DataPreparator(spark).transform_log(\n",
    "    \"data.csv\",\n",
    "    columns_names={\n",
    "        \"user_id\": \"user_id\",\n",
    "        \"item_id\": \"item_id\",\n",
    "        \"relevance\": \"relevance\",\n",
    "        \"timestamp\": \"timestamp\"\n",
    "    },\n",
    "    header=True,\n",
    "    format_type=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека содержит различные схемы валидации рекомендательных систем, встречающиеся в литературе.\n",
    "\n",
    "`UserSplitter` отбирает для теста некоторое количество или долю объектов для каждого пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:41:57.400738Z",
     "start_time": "2020-03-02T08:41:40.296822Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999703, 999703, 506)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sponge_bob_magic.splitters import UserSplitter\n",
    "\n",
    "splitter = UserSplitter(\n",
    "    drop_cold_items=True,\n",
    "    drop_cold_users=True,\n",
    "    item_test_size=1,\n",
    "    user_test_size=500,\n",
    "    seed=1234,\n",
    "    shuffle=True\n",
    ")\n",
    "train, test_input, test = splitter.split(log)\n",
    "(\n",
    "    train.count(), \n",
    "    test_input.count(), \n",
    "    test.count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF\n",
    "Простейший пример использования DL в рекомендациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:59:56.678520Z",
     "start_time": "2020-03-02T08:59:56.637541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sponge_bob_magic.models import NeuroMFRec\n",
    "\n",
    "nmf = NeuroMFRec(\n",
    "    learning_rate=0.01,\n",
    "    epochs=50,\n",
    "    embedding_dimension=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T09:07:06.431148Z",
     "start_time": "2020-03-02T08:59:58.784558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-Mar-20 11:59:58, root, DEBUG: Проверка датафреймов\n",
      "02-Mar-20 12:00:00, root, DEBUG: Предварительная стадия обучения (pre-fit)\n",
      "02-Mar-20 12:00:09, root, DEBUG: Основная стадия обучения (fit)\n",
      "02-Mar-20 12:00:09, root, DEBUG: Индексирование данных\n",
      "02-Mar-20 12:00:09, root, DEBUG: Составление батча:\n",
      "02-Mar-20 12:00:09, root, DEBUG: -- Запись\n",
      "02-Mar-20 12:00:10, root, DEBUG: -- Считывание\n",
      "02-Mar-20 12:00:11, root, DEBUG: Обучение модели\n",
      "02-Mar-20 12:00:11, root, DEBUG: -- Эпоха 0\n",
      "02-Mar-20 12:00:31, root, DEBUG: -- Текущее значение train loss: 0.9341\n",
      "02-Mar-20 12:00:32, root, DEBUG: -- Текущее значение val loss  : 0.7546\n",
      "02-Mar-20 12:00:32, root, DEBUG: -- Эпоха 1\n",
      "02-Mar-20 12:00:51, root, DEBUG: -- Текущее значение train loss: 0.4952\n",
      "02-Mar-20 12:00:52, root, DEBUG: -- Текущее значение val loss  : 0.3329\n",
      "02-Mar-20 12:00:52, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:00:52, root, DEBUG: -- Эпоха 2\n",
      "02-Mar-20 12:01:10, root, DEBUG: -- Текущее значение train loss: 0.2799\n",
      "02-Mar-20 12:01:12, root, DEBUG: -- Текущее значение val loss  : 0.2477\n",
      "02-Mar-20 12:01:12, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:01:12, root, DEBUG: -- Эпоха 3\n",
      "02-Mar-20 12:01:30, root, DEBUG: -- Текущее значение train loss: 0.2340\n",
      "02-Mar-20 12:01:32, root, DEBUG: -- Текущее значение val loss  : 0.2260\n",
      "02-Mar-20 12:01:32, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:01:32, root, DEBUG: -- Эпоха 4\n",
      "02-Mar-20 12:01:50, root, DEBUG: -- Текущее значение train loss: 0.2204\n",
      "02-Mar-20 12:01:51, root, DEBUG: -- Текущее значение val loss  : 0.2175\n",
      "02-Mar-20 12:01:51, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:01:51, root, DEBUG: -- Эпоха 5\n",
      "02-Mar-20 12:02:10, root, DEBUG: -- Текущее значение train loss: 0.2119\n",
      "02-Mar-20 12:02:11, root, DEBUG: -- Текущее значение val loss  : 0.2150\n",
      "02-Mar-20 12:02:11, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:02:11, root, DEBUG: -- Эпоха 6\n",
      "02-Mar-20 12:02:30, root, DEBUG: -- Текущее значение train loss: 0.2079\n",
      "02-Mar-20 12:02:32, root, DEBUG: -- Текущее значение val loss  : 0.2083\n",
      "02-Mar-20 12:02:32, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:02:32, root, DEBUG: -- Эпоха 7\n",
      "02-Mar-20 12:02:51, root, DEBUG: -- Текущее значение train loss: 0.2051\n",
      "02-Mar-20 12:02:53, root, DEBUG: -- Текущее значение val loss  : 0.2066\n",
      "02-Mar-20 12:02:53, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:02:53, root, DEBUG: -- Эпоха 8\n",
      "02-Mar-20 12:03:12, root, DEBUG: -- Текущее значение train loss: 0.2017\n",
      "02-Mar-20 12:03:14, root, DEBUG: -- Текущее значение val loss  : 0.2021\n",
      "02-Mar-20 12:03:14, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:03:14, root, DEBUG: -- Эпоха 9\n",
      "02-Mar-20 12:03:33, root, DEBUG: -- Текущее значение train loss: 0.1997\n",
      "02-Mar-20 12:03:34, root, DEBUG: -- Текущее значение val loss  : 0.2003\n",
      "02-Mar-20 12:03:35, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:03:35, root, DEBUG: -- Эпоха 10\n",
      "02-Mar-20 12:03:54, root, DEBUG: -- Текущее значение train loss: 0.1967\n",
      "02-Mar-20 12:03:55, root, DEBUG: -- Текущее значение val loss  : 0.1989\n",
      "02-Mar-20 12:03:55, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:03:55, root, DEBUG: -- Эпоха 11\n",
      "02-Mar-20 12:04:14, root, DEBUG: -- Текущее значение train loss: 0.1949\n",
      "02-Mar-20 12:04:15, root, DEBUG: -- Текущее значение val loss  : 0.1966\n",
      "02-Mar-20 12:04:15, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:04:15, root, DEBUG: -- Эпоха 12\n",
      "02-Mar-20 12:04:33, root, DEBUG: -- Текущее значение train loss: 0.1921\n",
      "02-Mar-20 12:04:35, root, DEBUG: -- Текущее значение val loss  : 0.1950\n",
      "02-Mar-20 12:04:35, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:04:35, root, DEBUG: -- Эпоха 13\n",
      "02-Mar-20 12:04:53, root, DEBUG: -- Текущее значение train loss: 0.1902\n",
      "02-Mar-20 12:04:55, root, DEBUG: -- Текущее значение val loss  : 0.1925\n",
      "02-Mar-20 12:04:55, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:04:55, root, DEBUG: -- Эпоха 14\n",
      "02-Mar-20 12:05:13, root, DEBUG: -- Текущее значение train loss: 0.1886\n",
      "02-Mar-20 12:05:14, root, DEBUG: -- Текущее значение val loss  : 0.1919\n",
      "02-Mar-20 12:05:14, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:05:14, root, DEBUG: -- Эпоха 15\n",
      "02-Mar-20 12:05:34, root, DEBUG: -- Текущее значение train loss: 0.1868\n",
      "02-Mar-20 12:05:36, root, DEBUG: -- Текущее значение val loss  : 0.1891\n",
      "02-Mar-20 12:05:36, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:05:36, root, DEBUG: -- Эпоха 16\n",
      "02-Mar-20 12:05:54, root, DEBUG: -- Текущее значение train loss: 0.1845\n",
      "02-Mar-20 12:05:56, root, DEBUG: -- Текущее значение val loss  : 0.1859\n",
      "02-Mar-20 12:05:56, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:05:56, root, DEBUG: -- Эпоха 17\n",
      "02-Mar-20 12:06:14, root, DEBUG: -- Текущее значение train loss: 0.1820\n",
      "02-Mar-20 12:06:15, root, DEBUG: -- Текущее значение val loss  : 0.1842\n",
      "02-Mar-20 12:06:15, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:06:15, root, DEBUG: -- Эпоха 18\n",
      "02-Mar-20 12:06:34, root, DEBUG: -- Текущее значение train loss: 0.1807\n",
      "02-Mar-20 12:06:36, root, DEBUG: -- Текущее значение val loss  : 0.1831\n",
      "02-Mar-20 12:06:36, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:06:36, root, DEBUG: -- Эпоха 19\n",
      "02-Mar-20 12:06:54, root, DEBUG: -- Текущее значение train loss: 0.1795\n",
      "02-Mar-20 12:06:55, root, DEBUG: -- Текущее значение val loss  : 0.1809\n",
      "02-Mar-20 12:06:55, root, DEBUG: -- Сохранение лучшей модели в файл\n",
      "02-Mar-20 12:06:55, root, DEBUG: -- Эпоха 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/sponge-bob-magic/sponge_bob_magic/models/base_rec.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, log, user_features, item_features)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Основная стадия обучения (fit)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sponge-bob-magic/sponge_bob_magic/models/neuromf_rec.py\u001b[0m in \u001b[0;36m_fit_partial\u001b[0;34m(self, log, user_features, item_features)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mvalid_user_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mvalid_item_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             )\n\u001b[1;32m    255\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_val_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sponge-bob-magic/sponge_bob_magic/models/neuromf_rec.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, train_user_batch, train_item_batch, valid_user_batch, valid_item_batch, optimizer)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-- Текущее значение train loss: %.4f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/sbm/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/sbm/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nmf.fit(\n",
    "    log=train,\n",
    "    user_features=None,\n",
    "    item_features=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:07:26.278582Z",
     "start_time": "2020-02-10T16:06:39.118983Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 148 ms, total: 1.39 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recs = nmf.predict(\n",
    "    log=train,\n",
    "    k=10,\n",
    "    users=test.select('user_id').distinct(),\n",
    "    items=test.select('item_id').distinct(),\n",
    "    context='no_context',\n",
    "    user_features=None,\n",
    "    item_features=None,\n",
    "    filter_seen_items=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке реализовано несколько различных метрик качества рекомендательных систем, встречающихся в литературе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:07:28.942205Z",
     "start_time": "2020-02-10T16:07:26.281475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039525691699604744"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sponge_bob_magic.metrics import HitRate\n",
    "\n",
    "hit_rate = HitRate()\n",
    "\n",
    "hit_rate(recs, test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:07:33.068902Z",
     "start_time": "2020-02-10T16:07:28.945088Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020361494493515788"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sponge_bob_magic.metrics import NDCG\n",
    "\n",
    "ndcg = NDCG()\n",
    "\n",
    "ndcg(recs, test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS\n",
    "Библиотека также содержит классические алгоритмы рекомендаций, например, матричную факторизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sponge_bob_magic.models.als_rec import ALSRec\n",
    "\n",
    "als = ALSRec(rank=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 12 ms, total: 36 ms\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "als.fit(\n",
    "    log=train,\n",
    "    user_features=None,\n",
    "    item_features=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 8 ms, total: 36 ms\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs = als.predict(\n",
    "    k=10,\n",
    "    users=test.select('user_id').distinct(),\n",
    "    items=test.select('item_id').distinct(),\n",
    "    context='no_context',\n",
    "    log=train,\n",
    "    user_features=None,\n",
    "    item_features=None,\n",
    "    filter_seen_items=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12055335968379446"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(recs, test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04913283620755998"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg(recs, test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Своя модель\n",
    "Для построения своей модели нужно использовать тот же самый split, что и для бейзлайнов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.toPandas().to_csv(\"train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id,item_id,relevance,timestamp,context\r\n",
      "1090,2433,3.0,2000-11-23 01:26:01,no_context\r\n",
      "1090,1247,4.0,2000-11-23 01:21:02,no_context\r\n",
      "1090,954,4.0,2000-11-23 01:21:50,no_context\r\n",
      "1090,3386,3.0,2000-11-23 01:14:07,no_context\r\n",
      "1090,1939,3.0,2000-11-23 01:20:32,no_context\r\n",
      "1090,2428,2.0,2000-11-23 01:27:11,no_context\r\n",
      "1090,1673,3.0,2000-11-23 01:05:15,no_context\r\n",
      "1090,1645,4.0,2000-11-23 01:33:11,no_context\r\n",
      "1090,1093,3.0,2000-11-23 01:26:44,no_context\r\n"
     ]
    }
   ],
   "source": [
    "!head train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь магия: можно взять train и обучить на нём свою любимую модель вне библиотеки\n",
    "\n",
    "Также нужно выдать рекомендации обученной моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.toPandas().to_csv(\"recs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно прочитать рекомендации в формате, поддерживаемом библиотекой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = DataPreparator(spark).transform_log(\n",
    "    \"recs.csv\",\n",
    "    columns_names={\n",
    "        \"user_id\": \"user_id\",\n",
    "        \"item_id\": \"item_id\",\n",
    "        \"relevance\": \"relevance\"\n",
    "    },\n",
    "    header=True,\n",
    "    format_type=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и сравнить качество своей модели с бейзлайнамии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12055335968379446"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(recs, test, k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbm",
   "language": "python",
   "name": "sbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "movielens_nmf.ipynb",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": null
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
