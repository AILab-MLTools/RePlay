{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RePlay Tutorial\n",
    "This notebook is designed to familiarize with the use of RePlay library, including:\n",
    "- creating SparkSession or passing your own session to RePlay\n",
    "- data preprocessing\n",
    "- dataset users and items re-indexing\n",
    "- data splitting\n",
    "- model training and inference\n",
    "- model optimization\n",
    "- model saving and loading\n",
    "- models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:01:45.639135Z",
     "start_time": "2020-02-10T16:01:45.612577Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from optuna.exceptions import ExperimentalWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
<<<<<<< HEAD
    "from replay.preprocessing.data_preparator import DataPreparator, Indexer\n",
    "from replay.metrics import Coverage, HitRate, NDCG, MAP, Experiment, OfflineMetrics\n",
    "from replay.utils.model_handler import save, load, save_indexer, load_indexer\n",
    "from replay.models import ItemKNN, SLIM\n",
    "from replay.models import ALSWrap\n",
=======
    "from replay.metrics import Coverage, HitRate, NDCG, MAP, Experiment\n",
    "from replay.utils.model_handler import save, load, save_encoder, load_encoder\n",
>>>>>>> added xfail to tests
    "from replay.utils.session_handler import get_spark_session, State \n",
    "from replay.splitters import TwoStageSplitter\n",
    "from replay.utils import convert2spark, get_log_info\n",
    "\n",
    "from replay.data import Dataset, FeatureHint, FeatureInfo, FeatureSchema, FeatureType\n",
    "from replay.data.dataset_utils import DatasetLabelEncoder\n",
    "\n",
    "from replay.models import ALSWrap, ItemKNN, SLIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RePlay uses Spark as a backend, and thus `SparkSession` should be created before RePlay running. Depends on your needs, you can choose, what to do about `SparkSession`.\n",
    "\n",
    "- Option 1: use default RePlay `SparkSession`\n",
    "- You can pass you own session to RePlay. Class `State` stores current session. Here you also have two options: \n",
    "    - Option 2: call `get_spark_session` to use default RePlay `SparkSession` with the custom driver memory and number of partitions \n",
    "    - Option 3: create `SparkSession` from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: use default RePlay's SparkSession\n",
    "It is the simplest and recommended way for the local execution mode. RePlay will get existing SparkSession or create the new one with default configuration.  Default session parameters are stated in `replay/utils/session_handler.py` file. The driver memory volume and number of partitions depends on available RAM and number of cores respectively.\n",
    "\n",
    "You could initiate default session creation explicitly, e.g. to preprocess spark DataFrames, get link to SparkUI and set logging level, but if you do not create it by yourself, the session will be created by RePlay anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/08 15:09:24 WARN Utils: Your hostname, ecs-eemalov-large resolves to a loopback address: 127.0.1.1; using 10.11.10.44 instead (on interface eth0)\n",
      "23/11/08 15:09:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/root/anaconda3/envs/replay/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/08 15:09:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/11/08 15:09:25 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/11/08 15:09:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f73d0f8a7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = State().session\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config_param(session, conf_name):\n",
    "    # get current spark session configuration:\n",
    "    conf = session.sparkContext.getConf().getAll()\n",
    "    # get num partitions\n",
    "    print(f'{conf_name}: {dict(conf)[conf_name]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.sql.shuffle.partitions: 48\n"
     ]
    }
   ],
   "source": [
    "print_config_param(spark, 'spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2:  Call `get_spark_session`  function to customize driver memory (spark.driver.memory) or number of partitions (spark.sql.shuffle.partitions) and use the default RePlay settings for other configuration parameters.\n",
    "We will specify 16 partitions and 4Gb driver memory for example. Pass created session to RePlay `State`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "session = get_spark_session(spark_memory=4, shuffle_partitions=16)\n",
    "spark = State(session).session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.sql.shuffle.partitions: 16\n"
     ]
    }
   ],
   "source": [
    "print_config_param(spark, 'spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Create your own session\n",
    "Pass created session to RePlay `State`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.sql.shuffle.partitions: 50\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "session = (\n",
    "        SparkSession.builder.config(\"spark.driver.memory\", \"8g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"50\")\n",
    "        .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "        .config(\"spark.driver.host\", \"localhost\")\n",
    "        .master(\"local[*]\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    "    )\n",
    "spark = State(session).session\n",
    "print_config_param(spark, 'spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will return to the default session config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f74b54e4370>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop()\n",
    "spark = State(get_spark_session()).session\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data preprocessing <a name='data-preparator'></a>\n",
    "We will use MovieLens 1m as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:42.041251Z",
     "start_time": "2020-02-10T15:59:09.230636Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ml1m_ratings.dat\", sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "users = pd.read_csv(\"data/ml1m_users.dat\", sep=\"\\t\", names=[\"user_id\", \"gender\", \"age\", \"occupation\", \"zip_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  occupation zip_code\n",
       "0        1      F    1          10    48067\n",
       "1        2      M   56          16    70072"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inner data format in RePlay is a spark dataframe. \n",
    "\n",
    "Columns with users' and items' identifiers are required for interactions. Optional columns are ``rating`` and interaction ``timestamp``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "|user_id|item_id|rating|timestamp|\n",
      "+-------+-------+------+---------+\n",
      "|      1|   1193|     5|978300760|\n",
      "|      1|    661|     3|978302109|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = convert2spark(df)\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+--------+\n",
      "|user_id|gender|age|occupation|zip_code|\n",
      "+-------+------+---+----------+--------+\n",
      "|      1|     F|  1|        10|   48067|\n",
      "|      2|     M| 56|        16|   70072|\n",
      "+-------+------+---+----------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_spark = convert2spark(users)\n",
    "users_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Filtering\n",
    "It is common to filter interactions by interaction date or rating value or remove items or users with small number of interactions. RePlay offers some filters presented in `replay.preprocessig.filters` module.\n",
    "We will leave ratings greater than or equal to 3 and remove users with 4 or fewer interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.preprocessing.filters import filter_by_min_count, filter_out_low_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total lines: 836478, total users: 6039, total items: 3628'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filter_out_low_ratings(df_spark, value=3, rating_column=\"rating\")\n",
    "get_log_info(filtered_df, user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08-Nov-23 15:09:55, replay, INFO: current threshold removes 1.1954887038272376e-06% of data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'total lines: 836477, total users: 6038, total items: 3628'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filter_by_min_count(filtered_df, num_entries=5, group_by='user_id')\n",
    "get_log_info(filtered_df, user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "|user_id|item_id|rating|timestamp|\n",
      "+-------+-------+------+---------+\n",
      "|     28|   1179|     4|978126422|\n",
      "|     28|   2550|     4|978125885|\n",
      "|     28|    648|     3|978982323|\n",
      "|     28|   3793|     4|978982233|\n",
      "|     28|    650|     3|978126224|\n",
      "|     28|   2997|     4|978125846|\n",
      "|     28|   3000|     3|978126172|\n",
      "|     28|      1|     3|978985309|\n",
      "|     28|   2132|     5|978985335|\n",
      "|     28|   1265|     4|978126107|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Split\n",
    "\n",
    "RePlay provides you with data splitters to reproduce a validation schemas widely-used in recommender systems. Splitters return cached dataframes to compute them once and re-use for models training, inference and metrics calculation.\n",
    "\n",
    "`TwoStageSplitter` takes ``second_divide_size`` of items for ``first_divide_size`` of users to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833977 2500\n"
     ]
    }
   ],
   "source": [
    "splitter = TwoStageSplitter(\n",
    "    query_column=\"user_id\",\n",
    "    item_column=\"item_id\",\n",
    "    first_divide_column=\"user_id\",\n",
    "    second_divide_column=\"item_id\",\n",
    "    drop_cold_items=True,\n",
    "    drop_cold_users=True,\n",
    "    second_divide_size=K,\n",
    "    first_divide_size=500,\n",
    "    seed=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "train_df, test_df = splitter.split(filtered_df)\n",
    "print(train_df.count(), test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.is_cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Dataset\n",
    "\n",
    "RePlay provides you universal container with interactions and user/item features for feeding data to models. Instance of Dataset requires dataframes of same type and description of features, written with FeatureSchema class. In next section it will help to encode whole dataset at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6038 3628\n"
     ]
    }
   ],
   "source": [
    "total_user_count = filtered_df.select(\"user_id\").distinct().count()\n",
    "total_item_count = filtered_df.select(\"item_id\").distinct().count()\n",
    "print(total_user_count, total_item_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_schema = FeatureSchema(\n",
    "    [\n",
    "        FeatureInfo(\n",
    "            column=\"user_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.QUERY_ID,\n",
    "            cardinality=total_user_count,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"item_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.ITEM_ID,\n",
    "            cardinality=total_item_count,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"rating\",\n",
    "            feature_type=FeatureType.NUMERICAL,\n",
    "            feature_hint=FeatureHint.RATING,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"timestamp\",\n",
    "            feature_type=FeatureType.NUMERICAL,\n",
    "            feature_hint=FeatureHint.TIMESTAMP,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=train_df,\n",
    "    query_features=None,\n",
    "    item_features=None,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=test_df,\n",
    "    query_features=None,\n",
    "    item_features=None,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5. DatasetLabelEncoder\n",
    "\n",
    "RePlay models require columns with users' and items' identifiers _(ids)_, those should be integers starting at zero without gaps. This is important for models that use sparse matrices and define the matrix size as the biggest seen user and item index. Storing _ids_ as integers also help to reduce memory usage compared to string _ids_.\n",
    "\n",
    "You should convert user and item _ids_ in interactions and features dataframes. RePlay offers DatasetLabelEncoder class to perform the _ids_ conversion and convert them back after recommendations generation (predict). The DatasetLabelEncoder will store label encoders for users and items (optionally for other columns) and allow transforming ids for users and items, which come after the encoder fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "encoder = DatasetLabelEncoder()\n",
    "train_dataset = encoder.fit_transform(train_dataset)\n",
    "test_dataset = encoder.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Models training\n",
    "\n",
    "#### SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = SLIM(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 384:==================================================>    (44 + 4) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 815 ms, sys: 69.5 ms, total: 884 ms\n",
      "Wall time: 20.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "slim.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 504:====================================>                  (32 + 0) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 ms, sys: 14.9 ms, total: 54.7 ms\n",
      "Wall time: 8.23 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs = slim.predict(\n",
    "    k=K,\n",
    "    queries=test_dataset.query_ids,\n",
    "    dataset=train_dataset,\n",
    "    filter_seen_items=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|user_id|item_id|            rating|\n",
      "+-------+-------+------------------+\n",
      "|    271|   1342|1.4208161339117393|\n",
      "|    271|   3000|  1.37722459857679|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
>>>>>>> updated notebooks
=======
>>>>>>> added xfail to tests
    }
   ],
   "source": [
    "recs.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RePlay implements some popular recommenders' quality metrics. They can be calculated directly as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG@5': 0.1783516989347853} {'MAP@5': 0.10512000000000002} {'HitRate@1': 0.25, 'HitRate@5': 0.562} {'Coverage@5': 0.149393605292172}\n"
     ]
=======
>>>>>>> added dataset into models interfaces
    }
   ],
   "source": [
    "print(\n",
    "    NDCG(K, user_column=\"user_idx\", item_column=\"item_idx\", score_column=\"relevance\")(recs, test),\n",
    "    MAP(K, user_column=\"user_idx\", item_column=\"item_idx\", score_column=\"relevance\")(recs, test),\n",
    "    HitRate([1, K], user_column=\"user_idx\", item_column=\"item_idx\", score_column=\"relevance\")(recs, test),\n",
    "    Coverage(K, user_column=\"user_idx\", item_column=\"item_idx\", score_column=\"relevance\")(recs, train),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to calculate multiple metrics for the same input data, then using ``OfflineMetrics`` class is much more efficient than calculating metrics individually.\n",
    "\n",
    "The result of the work coincides with the result of the work of individual metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG@5': 0.1783516989347853,\n",
       " 'MAP@5': 0.10512000000000002,\n",
       " 'HitRate@1': 0.25,\n",
       " 'HitRate@5': 0.562,\n",
       " 'Coverage@5': 0.149393605292172}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_metrics = OfflineMetrics(\n",
    "    [NDCG(K), MAP(K), HitRate([1, K]), Coverage(K)],\n",
    "    user_column=\"user_idx\", item_column=\"item_idx\", score_column=\"relevance\"\n",
    ")\n",
    "offline_metrics(recs, test, train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quick calculation of metrics and convenient comparison with other models, there is another class - ``Experiment``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = {\n",
    "    \"item_column\": train_dataset.feature_schema.item_id_column,\n",
    "    \"query_column\": train_dataset.feature_schema.query_id_column,\n",
    "    \"rating_column\": train_dataset.feature_schema.interactions_rating_column,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:07:28.942205Z",
     "start_time": "2020-02-10T16:07:26.281475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metrics = Experiment(\n",
<<<<<<< HEAD
    "    [\n",
    "        NDCG(K), \n",
    "        MAP(K), \n",
    "        HitRate([1, K]), \n",
    "        Coverage(K)\n",
    "    ],\n",
    "    test,\n",
    "    train,\n",
    "    user_column=\"user_idx\", item_column=\"item_idx\", score_column=\"relevance\"\n",
=======
    "    test_dataset, \n",
    "    {\n",
    "        NDCG(**col_names): K,\n",
    "        MAP(**col_names) : K,\n",
    "        HitRate(**col_names): [1, K],\n",
    "        Coverage(\n",
    "            interactions=train_dataset.interactions,\n",
    "            **col_names,\n",
    "        ): K\n",
    "    }\n",
>>>>>>> added xfail to tests
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 34,
>>>>>>> added xfail to tests
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "CPU times: user 74 ms, sys: 31 ms, total: 105 ms\n",
      "Wall time: 3.94 s\n"
=======
      "CPU times: user 59.5 ms, sys: 21.8 ms, total: 81.2 ms\n",
      "Wall time: 5.64 s\n"
>>>>>>> added dataset into models interfaces
=======
      "CPU times: user 182 ms, sys: 107 ms, total: 288 ms\n",
      "Wall time: 26.2 s\n"
>>>>>>> updated notebooks
=======
      "CPU times: user 76.8 ms, sys: 15.3 ms, total: 92.1 ms\n",
      "Wall time: 8.12 s\n"
>>>>>>> added xfail to tests
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>Coverage@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.113837</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.063476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Coverage@5  HitRate@1  HitRate@5  MAP@5    NDCG@5\n",
       "SLIM    0.113837      0.086      0.242  0.034  0.063476"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "metrics.add_result(\"SLIM\", recs)\n",
    "metrics.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# data split for hyperparameters optimization\n",
    "train_opt, val_opt = splitter.split(train_df)\n",
    "\n",
    "train_opt_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=train_opt,\n",
    ")\n",
    "val_opt_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=val_opt,\n",
    ")\n",
    "train_opt_dataset = encoder.transform(train_opt_dataset)\n",
    "val_opt_dataset = encoder.transform(val_opt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-08 15:15:10,431] A new study created in memory with name: no-name-e75ebc7a-4db1-47d1-9c3a-9222e5cf7bd7\n",
      "/root/work/replay_gitlab/RePlay/replay/optimization/optuna_objective.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  res[param] = suggest_fn(param, low=low, high=high)\n",
      "[I 2023-11-08 15:16:03,718] Trial 0 finished with value: 0.0019448038281215333 and parameters: {'beta': 0.01, 'lambda_': 0.01}. Best is trial 0 with value: 0.0019448038281215333.\n",
      "[I 2023-11-08 15:16:59,880] Trial 1 finished with value: 0.0019448038281215333 and parameters: {'beta': 0.14885702854659433, 'lambda_': 2.0270331887746544e-05}. Best is trial 0 with value: 0.0019448038281215333.\n",
      "[I 2023-11-08 15:17:50,299] Trial 2 finished with value: 0.0019448038281215333 and parameters: {'beta': 1.6900127682870672e-06, 'lambda_': 0.03491238597526555}. Best is trial 0 with value: 0.0019448038281215333.\n",
      "[I 2023-11-08 15:18:40,244] Trial 3 finished with value: 0.0022077398552003743 and parameters: {'beta': 0.00012878358743355014, 'lambda_': 0.06352770193460419}. Best is trial 3 with value: 0.0022077398552003743.\n",
      "[I 2023-11-08 15:19:32,825] Trial 4 finished with value: 0.0019448038281215333 and parameters: {'beta': 0.008038470576000071, 'lambda_': 0.0017300974696869095}. Best is trial 3 with value: 0.0022077398552003743.\n",
      "[I 2023-11-08 15:20:25,541] Trial 5 finished with value: 0.0019448038281215333 and parameters: {'beta': 7.5711780362021054e-06, 'lambda_': 0.005101391104157222}. Best is trial 3 with value: 0.0022077398552003743.\n",
      "[I 2023-11-08 15:21:24,944] Trial 6 finished with value: 0.001991921569191877 and parameters: {'beta': 0.5287778701511238, 'lambda_': 1.621901542205575e-06}. Best is trial 3 with value: 0.0022077398552003743.\n",
      "[I 2023-11-08 15:22:11,255] Trial 7 finished with value: 0.0022548575962707184 and parameters: {'beta': 0.08287653801805005, 'lambda_': 0.2871501039218261}. Best is trial 7 with value: 0.0022548575962707184.\n",
      "[I 2023-11-08 15:23:07,262] Trial 8 finished with value: 0.0019448038281215333 and parameters: {'beta': 0.0692718089425527, 'lambda_': 1.299089383626244e-05}. Best is trial 7 with value: 0.0022548575962707184.\n",
      "[I 2023-11-08 15:27:34,350] Trial 9 finished with value: 0.0020809118739969264 and parameters: {'beta': 1.1213330127811002e-05, 'lambda_': 1.3845924533733034e-06}. Best is trial 7 with value: 0.0022548575962707184.\n",
      "[I 2023-11-08 15:28:18,902] Trial 10 finished with value: 0.0017881897300235667 and parameters: {'beta': 1.8734922528752633, 'lambda_': 1.1951238621944087}. Best is trial 7 with value: 0.0022548575962707184.\n",
      "[I 2023-11-08 15:29:06,827] Trial 11 finished with value: 0.0022548575962707184 and parameters: {'beta': 0.0002635288141280063, 'lambda_': 0.2907567850177058}. Best is trial 7 with value: 0.0022548575962707184.\n",
      "[I 2023-11-08 15:29:52,068] Trial 12 finished with value: 0.0017881897300235667 and parameters: {'beta': 0.00029484815961077935, 'lambda_': 0.7427685500858643}. Best is trial 7 with value: 0.0022548575962707184.\n",
      "[I 2023-11-08 15:30:42,038] Trial 13 finished with value: 0.0022077398552003743 and parameters: {'beta': 0.0015279171871045818, 'lambda_': 0.1127042470212914}. Best is trial 7 with value: 0.0022548575962707184.\n",
      "[I 2023-11-08 15:31:29,778] Trial 14 finished with value: 0.001915017711227015 and parameters: {'beta': 2.9258931173428815, 'lambda_': 0.22416432811586437}. Best is trial 7 with value: 0.0022548575962707184.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 1.4 s, total: 15.8 s\n",
      "Wall time: 16min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
<<<<<<< HEAD
    "best_params = slim.optimize(train_opt, val_opt, criterion=NDCG, k=K, budget=15)"
=======
    "best_params = slim.optimize(train_opt_dataset, val_opt_dataset, criterion=NDCG, k=K, budget=15)"
>>>>>>> added xfail to tests
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 37,
>>>>>>> added xfail to tests
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "{'beta': 0.110323973849151, 'lambda_': 9.739888703501135e-05}"
=======
       "{'beta': 0.01, 'lambda_': 0.01}"
>>>>>>> added dataset into models interfaces
=======
       "{'beta': 0.061429815496712774, 'lambda_': 0.02613996164121192}"
>>>>>>> updated notebooks
      ]
     },
     "execution_count": 42,
=======
       "{'beta': 0.08287653801805005, 'lambda_': 0.2871501039218261}"
      ]
     },
     "execution_count": 37,
>>>>>>> added xfail to tests
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Compare with previous"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 38,
>>>>>>> added xfail to tests
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_evaluate(model, experiment, name):\n",
    "    model.fit(train_dataset)\n",
    "\n",
    "    recs = model.predict(\n",
    "        dataset=train_dataset,\n",
    "        k=K,\n",
    "        queries=test_dataset.query_ids,\n",
    "        filter_seen_items=False\n",
    "    )\n",
    "\n",
    "    experiment.add_result(name, recs)\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 39,
>>>>>>> added xfail to tests
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "CPU times: user 1.12 s, sys: 111 ms, total: 1.23 s\n",
      "Wall time: 22.3 s\n"
=======
      "CPU times: user 944 ms, sys: 54.9 ms, total: 999 ms\n",
      "Wall time: 20.7 s\n"
>>>>>>> added dataset into models interfaces
=======
      "CPU times: user 2.28 s, sys: 375 ms, total: 2.65 s\n",
      "Wall time: 1min 4s\n"
>>>>>>> updated notebooks
=======
      "CPU times: user 927 ms, sys: 110 ms, total: 1.04 s\n",
      "Wall time: 31.8 s\n"
>>>>>>> added xfail to tests
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverage@5</th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>NDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>0.178352</td>\n",
       "      <td>0.105120</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.149394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM_optimized</th>\n",
       "      <td>0.177323</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.138368</td>\n",
=======
       "      <td>0.153295</td>\n",
       "      <td>0.226</td>\n",
=======
       "      <td>0.151916</td>\n",
       "      <td>0.220</td>\n",
>>>>>>> updated notebooks
       "      <td>0.556</td>\n",
       "      <td>0.100060</td>\n",
       "      <td>0.172416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM_optimized</th>\n",
<<<<<<< HEAD
       "      <td>0.153295</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.100167</td>\n",
       "      <td>0.171518</td>\n",
>>>>>>> added dataset into models interfaces
=======
       "      <td>0.141163</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.099273</td>\n",
       "      <td>0.172007</td>\n",
>>>>>>> updated notebooks
=======
       "      <td>0.113837</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.063476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM_optimized</th>\n",
       "      <td>0.063120</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>0.061920</td>\n",
>>>>>>> added xfail to tests
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                  NDCG@5     MAP@5  HitRate@1  HitRate@5  Coverage@5\n",
       "SLIM            0.178352  0.105120       0.25      0.562    0.149394\n",
       "SLIM_optimized  0.177323  0.105453       0.24      0.552    0.138368"
=======
       "                Coverage@5  HitRate@1  HitRate@5     MAP@5    NDCG@5\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "SLIM              0.153295      0.226      0.556  0.100167  0.171518\n",
       "SLIM_optimized    0.153295      0.226      0.556  0.100167  0.171518"
>>>>>>> added dataset into models interfaces
=======
       "SLIM              0.151916      0.220      0.556  0.100060  0.172416\n",
       "SLIM_optimized    0.141163      0.214      0.568  0.099273  0.172007"
>>>>>>> updated notebooks
      ]
     },
     "execution_count": 44,
=======
       "SLIM              0.113837      0.086      0.242  0.034000  0.063476\n",
       "SLIM_optimized    0.063120      0.078      0.244  0.032753  0.061920"
      ]
     },
     "execution_count": 39,
>>>>>>> added xfail to tests
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recs = fit_predict_evaluate(SLIM(**best_params, seed=SEED), metrics, 'SLIM_optimized')\n",
    "recs.cache() # caching for further processing\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized model was better on the validation dataset, but shows comparable quality on test (better by HitRate@5 and worse by the other quality metrics). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getting final recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to original user and item identifiers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 40,
>>>>>>> added xfail to tests
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "+-------+-------+------------------+\n",
      "|user_id|item_id|         relevance|\n",
      "+-------+-------+------------------+\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "|     33|   1036|0.9123513319313026|\n",
      "|     33|    457|0.8879526805724316|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 319 ms, sys: 125 ms, total: 444 ms\n",
      "Wall time: 1.03 s\n"
=======
      "|    639|    377|0.8926379418664969|\n",
      "|    639|      1|0.8857830180404516|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 327 ms, sys: 47.2 ms, total: 375 ms\n",
      "Wall time: 882 ms\n"
>>>>>>> added dataset into models interfaces
=======
      "|   5107|    527| 1.046002020356746|\n",
      "|   5107|   2599|0.9492305434804991|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 754 ms, sys: 296 ms, total: 1.05 s\n",
      "Wall time: 6.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
>>>>>>> updated notebooks
=======
      "+------------------+-------+-------+\n",
      "|            rating|user_id|item_id|\n",
      "+------------------+-------+-------+\n",
      "|1.1819098819880203|    949|    260|\n",
      "|1.0638413372139444|    949|   1196|\n",
      "+------------------+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 113 ms, sys: 624 µs, total: 114 ms\n",
      "Wall time: 540 ms\n"
>>>>>>> added xfail to tests
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs = encoder.query_and_item_id_encoder.inverse_transform(recs)\n",
    "recs.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to pandas or save"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 41,
>>>>>>> added xfail to tests
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>33</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.912351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>457</td>\n",
       "      <td>0.887953</td>\n",
=======
       "      <td>639</td>\n",
       "      <td>377</td>\n",
       "      <td>0.892638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885783</td>\n",
>>>>>>> added dataset into models interfaces
=======
       "      <td>5107</td>\n",
       "      <td>527</td>\n",
       "      <td>1.046002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5107</td>\n",
       "      <td>2599</td>\n",
       "      <td>0.949231</td>\n",
>>>>>>> updated notebooks
=======
       "      <td>1.181910</td>\n",
       "      <td>949</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.150479</td>\n",
       "      <td>949</td>\n",
       "      <td>2571</td>\n",
>>>>>>> added xfail to tests
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   user_id  item_id  relevance\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "0       33     1036   0.912351\n",
       "1       33      457   0.887953"
=======
       "0      639      377   0.892638\n",
       "1      639        1   0.885783"
>>>>>>> added dataset into models interfaces
=======
       "0     5107      527   1.046002\n",
       "1     5107     2599   0.949231"
>>>>>>> updated notebooks
      ]
     },
     "execution_count": 46,
=======
       "     rating  user_id  item_id\n",
       "0  1.181910      949      260\n",
       "1  1.150479      949     2571"
      ]
     },
     "execution_count": 41,
>>>>>>> added xfail to tests
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_pd = recs.toPandas()\n",
    "recs_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "[Stage 6321:==========================>                         (74 + 49) / 144]\r"
=======
      "[Stage 6187:>                                                     (0 + 16) / 48]\r"
>>>>>>> added dataset into models interfaces
=======
      "\r\n",
      "[Stage 2751:>                                                      (0 + 8) / 24]\r"
>>>>>>> updated notebooks
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "CPU times: user 6.89 ms, sys: 7.88 ms, total: 14.8 ms\n",
      "Wall time: 1.91 s\n"
=======
      "CPU times: user 5.17 ms, sys: 865 µs, total: 6.03 ms\n",
      "Wall time: 1.24 s\n"
>>>>>>> added dataset into models interfaces
=======
      "CPU times: user 4.62 ms, sys: 4.24 ms, total: 8.86 ms\n",
      "Wall time: 2.75 s\n"
>>>>>>> updated notebooks
=======
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.78 ms, sys: 0 ns, total: 6.78 ms\n",
      "Wall time: 1.24 s\n"
>>>>>>> added xfail to tests
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs.write.parquet(path='./slim_recs.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized model was better on the validation dataset, but shows comparable quality on test (better by HitRate@5 and worse by the other quality metrics). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 4. Getting final recommendations "
=======
    "RePlay allows saving and loading fitted models with `save` and `load` functions of `model_handler` module. Model is saved as a folder with all necessary parameters and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 ms, sys: 0 ns, total: 2.9 ms\n",
      "Wall time: 3.23 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "save_encoder(encoder, \"./encoder\")\n",
    "encoder_loaded = load_encoder(\"./encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59 ms, sys: 14.4 ms, total: 73.4 ms\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save(slim, path='./slim_best_params')\n",
    "slim_loaded = load('./slim_best_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08287653801805005, 0.2871501039218261)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slim_loaded.beta, slim_loaded.lambda_"
>>>>>>> added dataset into models interfaces
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "code",
   "execution_count": 46,
>>>>>>> added xfail to tests
   "metadata": {},
<<<<<<< HEAD
=======
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|user_id|item_id|            rating|\n",
      "+-------+-------+------------------+\n",
      "|    271|   1032| 0.671871745783729|\n",
      "|    271|    730|0.5642839036157286|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 62.7 ms, sys: 8.47 ms, total: 71.2 ms\n",
      "Wall time: 7.49 s\n"
     ]
    }
   ],
>>>>>>> added dataset into models interfaces
   "source": [
<<<<<<< HEAD
    "### Return to original user and item identifiers"
=======
    "%%time\n",
    "pred_from_loaded = slim_loaded.predict(\n",
    "    k=K,\n",
    "    queries=test_dataset.query_ids,\n",
    "    dataset=train_dataset,\n",
    "    filter_seen_items=True)\n",
    "pred_from_loaded.show(2)"
>>>>>>> added xfail to tests
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2721:======================================>               (17 + 7) / 24]\r"
     ]
    },
    {
=======
>>>>>>> added dataset into models interfaces
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2868:==========================================>           (19 + 5) / 24]\r"
     ]
    },
    {
>>>>>>> updated notebooks
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|user_id|item_id|         relevance|\n",
      "+-------+-------+------------------+\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "|   5107|    527| 1.046002020356746|\n",
      "|   5107|   2599|0.9492305434804991|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 754 ms, sys: 296 ms, total: 1.05 s\n",
      "Wall time: 6.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
=======
      "|    639|      1| 0.772206879664964|\n",
      "|    639|    377|0.7198939329475659|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 234 ms, sys: 82.1 ms, total: 316 ms\n",
      "Wall time: 737 ms\n"
>>>>>>> added dataset into models interfaces
=======
      "|   5107|    527|1.0362708717674016|\n",
      "|   5107|   2599|0.9560245729412186|\n",
      "+-------+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 886 ms, sys: 341 ms, total: 1.23 s\n",
      "Wall time: 7.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
>>>>>>> updated notebooks
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-------+\n",
      "|            rating|user_id|item_id|\n",
      "+------------------+-------+-------+\n",
      "| 0.671871745783729|    949|   1608|\n",
      "|0.5642839036157286|    949|   3114|\n",
      "+------------------+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 224 ms, sys: 7.89 ms, total: 232 ms\n",
      "Wall time: 767 ms\n"
>>>>>>> added xfail to tests
     ]
    }
   ],
   "source": [
    "%%time\n",
<<<<<<< HEAD
    "recs = indexer.inverse_transform(recs)\n",
=======
    "recs = encoder_loaded.query_and_item_id_encoder.inverse_transform(pred_from_loaded)\n",
>>>>>>> added xfail to tests
    "recs.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Convert to pandas or save"
=======
    "## 5. Other RePlay models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS\n",
    "Commonly-used matrix factorization algorithm."
>>>>>>> added dataset into models interfaces
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
=======
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/replay/lib/python3.9/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 117 ms, sys: 4.71 ms, total: 122 ms\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
>>>>>>> added dataset into models interfaces
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>relevance</th>\n",
=======
       "      <th>Coverage@5</th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>NDCG@5</th>\n",
>>>>>>> added dataset into models interfaces
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
       "      <td>5107</td>\n",
       "      <td>527</td>\n",
       "      <td>1.046002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5107</td>\n",
       "      <td>2599</td>\n",
       "      <td>0.949231</td>\n",
=======
       "      <th>SLIM</th>\n",
       "      <td>0.153295</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.100167</td>\n",
       "      <td>0.171518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM_optimized</th>\n",
       "      <td>0.153295</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.100167</td>\n",
       "      <td>0.171518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALS</th>\n",
       "      <td>0.191618</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.097473</td>\n",
       "      <td>0.168406</td>\n",
>>>>>>> added dataset into models interfaces
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                  NDCG@5     MAP@5  HitRate@1  HitRate@5  Coverage@5\n",
       "SLIM            0.178352  0.105120      0.250      0.562    0.149394\n",
       "SLIM_optimized  0.177323  0.105453      0.240      0.552    0.138368\n",
       "ALS             0.160422  0.092940      0.216      0.524    0.183848"
      ]
     },
     "execution_count": 53,
=======
       "                Coverage@5  HitRate@1  HitRate@5     MAP@5    NDCG@5\n",
       "SLIM              0.153295      0.226      0.556  0.100167  0.171518\n",
       "SLIM_optimized    0.153295      0.226      0.556  0.100167  0.171518\n",
       "ALS               0.191618      0.232      0.538  0.097473  0.168406"
      ]
     },
     "execution_count": 51,
>>>>>>> added dataset into models interfaces
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> updated notebooks
=======
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/replay/lib/python3.9/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 163 ms, sys: 64 ms, total: 227 ms\n",
      "Wall time: 44.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverage@5</th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>NDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALS</th>\n",
       "      <td>0.160970</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.034867</td>\n",
       "      <td>0.068995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.113837</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.063476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM_optimized</th>\n",
       "      <td>0.063120</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>0.061920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Coverage@5  HitRate@1  HitRate@5     MAP@5    NDCG@5\n",
       "ALS               0.160970      0.072      0.286  0.034867  0.068995\n",
       "SLIM              0.113837      0.086      0.242  0.034000  0.063476\n",
       "SLIM_optimized    0.063120      0.078      0.244  0.032753  0.061920"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> added xfail to tests
   "source": [
    "%%time\n",
    "recs = fit_predict_evaluate(ALSWrap(rank=100, seed=SEED), metrics, 'ALS')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ItemKNN\n",
    "Commonly-used item-based recommender"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
=======
   "execution_count": 49,
>>>>>>> added xfail to tests
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 43 ms, total: 238 ms\n",
      "Wall time: 36.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverage@5</th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>NDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALS</th>\n",
       "      <td>0.160970</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.034867</td>\n",
       "      <td>0.068995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.113837</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.063476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM_optimized</th>\n",
       "      <td>0.063120</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>0.061920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN</th>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.058481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Coverage@5  HitRate@1  HitRate@5     MAP@5    NDCG@5\n",
       "ALS               0.160970      0.072      0.286  0.034867  0.068995\n",
       "SLIM              0.113837      0.086      0.242  0.034000  0.063476\n",
       "SLIM_optimized    0.063120      0.078      0.244  0.032753  0.061920\n",
       "ItemKNN           0.037762      0.070      0.238  0.029853  0.058481"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recs = fit_predict_evaluate(ItemKNN(num_neighbours=100), metrics, 'ItemKNN')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Compare RePlay models with others\n",
    "To easily evaluate recommendations obtained from other sources, read and pass these recommendations to ``Experiment``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverage@5</th>\n",
       "      <th>HitRate@1</th>\n",
       "      <th>HitRate@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>NDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALS</th>\n",
       "      <td>0.160970</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.034867</td>\n",
       "      <td>0.068995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM</th>\n",
       "      <td>0.113837</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.063476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLIM_optimized</th>\n",
       "      <td>0.063120</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>0.061920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNN</th>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.058481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_model</th>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.027313</td>\n",
       "      <td>0.055090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Coverage@5  HitRate@1  HitRate@5     MAP@5    NDCG@5\n",
       "ALS               0.160970      0.072      0.286  0.034867  0.068995\n",
       "SLIM              0.113837      0.086      0.242  0.034000  0.063476\n",
       "SLIM_optimized    0.063120      0.078      0.244  0.032753  0.061920\n",
       "ItemKNN           0.037762      0.070      0.238  0.029853  0.058481\n",
       "my_model          0.037762      0.056      0.238  0.027313  0.055090"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.add_result(\"my_model\", recs.withColumn(\"rating\", sf.rand()))\n",
    "metrics.results.sort_values(\"NDCG@5\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "name": "movielens_nmf.ipynb",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "null"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
