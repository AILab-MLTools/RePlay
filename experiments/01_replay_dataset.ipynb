{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RePlay Tutorial\n",
    "This notebook is designed to familiarize with the use of RePlay library, including:\n",
    "- creating SparkSession or passing your own session to RePlay\n",
    "- data preprocessing\n",
    "- dataset users and items re-indexing\n",
    "- data splitting\n",
    "- model training and inference\n",
    "- model optimization\n",
    "- model saving and loading\n",
    "- models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:01:45.639135Z",
     "start_time": "2020-02-10T16:01:45.612577Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from optuna.exceptions import ExperimentalWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from replay.preprocessing.data_preparator import DataPreparator, Indexer\n",
    "from replay.metrics import Coverage, HitRate, NDCG, MAP, Experiment\n",
    "from replay.utils.model_handler import save, load, save_indexer, load_indexer\n",
    "from replay.utils.session_handler import get_spark_session, State \n",
    "from replay.splitters import UserSplitter\n",
    "from replay.utils import convert2spark, get_log_info\n",
    "\n",
    "from replay.data import Dataset, FeatureHint, FeatureInfo, FeatureSchema, FeatureSource, FeatureType\n",
    "from replay.data.dataset_utils import DatasetLabelEncoder\n",
    "\n",
    "from replay.models import (\n",
    "    ALSWrap, \n",
    "    ADMMSLIM, \n",
    "    ItemKNN,\n",
    "    LightFMWrap, \n",
    "    MultVAE, \n",
    "    NeuroMF, \n",
    "    SLIM, \n",
    "    PopRec, \n",
    "    RandomRec,\n",
    "    UCB,\n",
    "    UserPopRec,\n",
    "    Wilson, \n",
    "    Word2VecRec,\n",
    ")\n",
    "\n",
    "from replay.models.base_rec import HybridRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RePlay uses Spark as a backend, and thus `SparkSession` should be created before RePlay running. Depends on your needs, you can choose, what to do about `SparkSession`.\n",
    "\n",
    "- Option 1: use default RePlay `SparkSession`\n",
    "- You can pass you own session to RePlay. Class `State` stores current session. Here you also have two options: \n",
    "    - Option 2: call `get_spark_session` to use default RePlay `SparkSession` with the custom driver memory and number of partitions \n",
    "    - Option 3: create `SparkSession` from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: use default RePlay's SparkSession\n",
    "It is the simplest and recommended way for the local execution mode. RePlay will get existing SparkSession or create the new one with default configuration.  Default session parameters are stated in `replay/utils/session_handler.py` file. The driver memory volume and number of partitions depends on available RAM and number of cores respectively.\n",
    "\n",
    "You could initiate default session creation explicitly, e.g. to preprocess spark DataFrames, get link to SparkUI and set logging level, but if you do not create it by yourself, the session will be created by RePlay anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = State().session\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config_param(session, conf_name):\n",
    "    # get current spark session configuration:\n",
    "    conf = session.sparkContext.getConf().getAll()\n",
    "    # get num partitions\n",
    "    print(f'{conf_name}: {dict(conf)[conf_name]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_config_param(spark, 'spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2:  Call `get_spark_session`  function to customize driver memory (spark.driver.memory) or number of partitions (spark.sql.shuffle.partitions) and use the default RePlay settings for other configuration parameters.\n",
    "We will specify 16 partitions and 4Gb driver memory for example. Pass created session to RePlay `State`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "session = get_spark_session(spark_memory=4, shuffle_partitions=16)\n",
    "spark = State(session).session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_config_param(spark, 'spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Create your own session\n",
    "Pass created session to RePlay `State`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "session = (\n",
    "        SparkSession.builder.config(\"spark.driver.memory\", \"8g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"50\")\n",
    "        .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "        .config(\"spark.driver.host\", \"localhost\")\n",
    "        .master(\"local[*]\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    "    )\n",
    "spark = State(session).session\n",
    "print_config_param(spark, 'spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will return to the default session config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "spark = State(get_spark_session()).session\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data preprocessing <a name='data-preparator'></a>\n",
    "We will use MovieLens 1m as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:42.041251Z",
     "start_time": "2020-02-10T15:59:09.230636Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ml1m_ratings.dat\", sep=\"\\t\", names=[\"user_id\", \"item_id\", \"relevance\", \"timestamp\"])\n",
    "users = pd.read_csv(\"data/ml1m_users.dat\", sep=\"\\t\", names=[\"user_id\", \"gender\", \"age\", \"occupation\", \"zip_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.user_id.nunique(), df.item_id.nunique(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. DataPreparator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inner data format in RePlay is a spark dataframe. \n",
    "\n",
    "Columns with users' and items' identifiers are required for interaction log. Original user and item identifiers should be named as `user_id` and `item_id`. Those identifiers in section [0.3. Indexing](#indexing) will be converted to integer identifiers, which will be named `user_idx`, `item_idx`. Optional columns for interaction matrix are ``relevance`` and interaction ``timestamp``.\n",
    "\n",
    "DataFrames with user or item features should have column `user_id` or `item_id` respectively.\n",
    "\n",
    "We implemented DataPreparator class to convert pandas dataframes to spark format and preprocess the data, including renaming/creation of required and optional interaction matrix columns, null check and dates parsing. It is an optional step, if you already have data in Spark DataFrame format, could rename the above mentioned columns, and confident in completeness and quality of the data, skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparator = DataPreparator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactions log preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log = preparator.transform(columns_mapping={'user_id': 'user_id',\n",
    "                                      'item_id': 'item_id',\n",
    "                                      'relevance': 'relevance',\n",
    "                                      'timestamp': 'timestamp'\n",
    "                                     }, \n",
    "                           data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_info(log, user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, `userId` was renamed to `user_id` and `timestamp` was converted to `TimestampType`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature dataframe preprocessing\n",
    "To transform feature dataframes you could also use DataPreparator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = preparator.transform(columns_mapping={'user_id': 'user_id'},\n",
    "                                     data=users)\n",
    "user_features.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the DataPreparator is optional, you could convert dataFrame to spark with ``convert_to_spark`` from ``replay.utils.spark_utils.py`` and manually rename columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same result without DataPreparator\n",
    "convert2spark(users).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Filtering\n",
    "It is common to filter interactions log by interaction date or rating value or remove items or users with small number of interactions. RePlay offers some filters presented in `replay.preprocessig.filters` module.\n",
    "We will leave ratings greater than or equal to 3 and remove users with 4 or fewer interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.preprocessing.filters import filter_by_min_count, filter_out_low_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = filter_out_low_ratings(log, value=3)\n",
    "get_log_info(log, user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log = filter_by_min_count(log, num_entries=5, group_by='user_id')\n",
    "get_log_info(log, user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='indexing'></a>\n",
    "### 0.3. Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RePlay models require columns with users' and items' identifiers _(ids)_ to be named as `user_idx` and `item_idx`. Those _ids_ should be integers starting at zero without gaps. This is important for models that use sparse matrices and define the matrix size as the biggest seen user and item index. Storing _ids_ as integers also help to reduce memory usage compared to string _ids_.\n",
    "\n",
    "You should convert user and item _ids_ in interaction's log and feature dataframes. RaPlay offers Indexer class to perform the _ids_ conversion and convert them back after recommendations generation (predict). The Indexer will store label encoders for users and items and allow transforming ids for users and items, which come after the Indexer fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer(user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all available user and item ids from log and features and pass them to Indexer. The _ids_ could repeat, the indexes will be ordered by label frequencies, so the most frequent label gets index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "indexer.fit(users=log.select('user_id').unionByName(user_features.select('user_id')),\n",
    "            items=log.select('item_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_replay = indexer.transform(df=log)\n",
    "log_replay.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "user_features_replay = indexer.transform(df=user_features)\n",
    "user_features_replay.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RePlay provides you with data splitters to reproduce a validation schemas widely-used in recommender systems. Splitters return cached dataframes to compute them once and re-use for models training, inference and metrics calculation.\n",
    "\n",
    "`UserSplitter` takes ``item_test_size`` items for ``user_test_size`` user to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:50.986401Z",
     "start_time": "2020-02-10T15:59:42.042998Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "splitter = UserSplitter(\n",
    "    drop_cold_items=True,\n",
    "    drop_cold_users=True,\n",
    "    item_test_size=K,\n",
    "    user_test_size=500,\n",
    "    seed=SEED,\n",
    "    shuffle=False\n",
    ")\n",
    "train, test = splitter.split(log_replay)\n",
    "print(train.count(), test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.is_cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5. Alternative preparations with Dataset and DatasetLabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.preprocessing.filters import filter_by_min_count, filter_out_low_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = convert2spark(df)\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_spark = convert2spark(users)\n",
    "users_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_out_low_ratings(df_spark, value=3, rating_column=\"relevance\")\n",
    "get_log_info(filtered_df, user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_by_min_count(filtered_df, num_entries=5, group_by='user_id')\n",
    "get_log_info(filtered_df, user_col='user_id', item_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = UserSplitter(\n",
    "    user_col=\"user_id\",\n",
    "    item_col=\"item_id\",\n",
    "    date_col=\"timestamp\",\n",
    "    drop_cold_items=True,\n",
    "    drop_cold_users=True,\n",
    "    item_test_size=K,\n",
    "    user_test_size=500,\n",
    "    seed=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "train_df, test_df = splitter.split(filtered_df)\n",
    "print(train_df.count(), test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user_count = filtered_df.select(\"user_id\").distinct().count()\n",
    "total_item_count = filtered_df.select(\"item_id\").distinct().count()\n",
    "print(total_user_count, total_item_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_schema = FeatureSchema(\n",
    "    [\n",
    "        FeatureInfo(\n",
    "            column=\"user_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.QUERY_ID,\n",
    "            cardinality=total_user_count,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"item_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.ITEM_ID,\n",
    "            cardinality=total_item_count,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"relevance\",\n",
    "            feature_type=FeatureType.NUMERICAL,\n",
    "            feature_hint=FeatureHint.RATING,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"timestamp\",\n",
    "            feature_type=FeatureType.NUMERICAL,\n",
    "            feature_hint=FeatureHint.TIMESTAMP,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"gender\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"zip_code\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "feature_schema = FeatureSchema(\n",
    "    [\n",
    "        FeatureInfo(\n",
    "            column=\"user_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.QUERY_ID,\n",
    "            cardinality=total_user_count,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"item_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.ITEM_ID,\n",
    "            cardinality=total_item_count,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"relevance\",\n",
    "            feature_type=FeatureType.NUMERICAL,\n",
    "            feature_hint=FeatureHint.RATING,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"timestamp\",\n",
    "            feature_type=FeatureType.NUMERICAL,\n",
    "            feature_hint=FeatureHint.TIMESTAMP,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=train_df,\n",
    "    query_features=None,\n",
    "    item_features=None,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    feature_schema=feature_schema,\n",
    "    interactions=test_df,\n",
    "    query_features=None,\n",
    "    item_features=None,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = DatasetLabelEncoder()\n",
    "train_dataset = encoder.fit_transform(train_dataset)\n",
    "test_dataset = encoder.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    train_dataset.feature_schema.item_id_column,\n",
    "    train_dataset.feature_schema.query_id_column,\n",
    "    train_dataset.feature_schema.interactions_rating_column,\n",
    "    train_dataset.feature_schema.interactions_timestamp_column,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Models training\n",
    "\n",
    "#### SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = SLIM(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "slim.fit(log=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "recs = slim.predict(\n",
    "    k=K,\n",
    "    users=test.select('user_idx').distinct(),\n",
    "    log=train,\n",
    "    filter_seen_items=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RePlay implements some popular recommenders' quality metrics. Use pure metrics or calculate a set of chosen metrics and compare models with the ``Experiment`` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = {\n",
    "    \"item_col\": train_dataset.feature_schema.item_id_column,\n",
    "    \"query_col\": train_dataset.feature_schema.query_id_column,\n",
    "    \"rating_col\": train_dataset.feature_schema.interactions_rating_column,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T16:07:28.942205Z",
     "start_time": "2020-02-10T16:07:26.281475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metrics = Experiment(test_dataset, {NDCG(**col_names): K,\n",
    "                            MAP(**col_names) : K,\n",
    "                            HitRate(**col_names): [1, K],\n",
    "                            Coverage(\n",
    "                                log=train_dataset.interactions,\n",
    "                                **col_names\n",
    "                            ): K\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics.add_result(\"SLIM\", recs)\n",
    "metrics.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split for hyperparameters optimization\n",
    "# train_opt, val_opt = splitter.split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# best_params = slim.optimize(train_opt, val_opt, criterion=NDCG(), k=K, budget=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Compare with previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_evaluate(model, experiment, name):\n",
    "    model.fit(train_dataset)\n",
    "\n",
    "    recs = model.predict(\n",
    "        dataset=train_dataset,\n",
    "        k=K,\n",
    "        users=test_dataset.query_ids,\n",
    "        filter_seen_items=False\n",
    "    )\n",
    "\n",
    "    experiment.add_result(name, recs)\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# recs = fit_predict_evaluate(SLIM(**best_params, seed=SEED), metrics, 'SLIM_optimized')\n",
    "# recs.cache() #caching for further processing\n",
    "# metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized model was better on the validation dataset, but shows comparable quality on test (better by HitRate@5 and worse by the other quality metrics). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getting final recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to original user and item identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# recs = indexer.inverse_transform(recs)\n",
    "# recs.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to pandas or save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recs_pd = recs.toPandas()\n",
    "# recs_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# recs.write.parquet(path='./slim_recs.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save and load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RePlay allows saving and loading fitted models with `save` and `load` functions of `model_handler` module. Model is saved as a folder with all necessary parameters and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# save_indexer(indexer, './indexer_ml1')\n",
    "# indexer = load_indexer('./indexer_ml1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# save(slim, path='./slim_best_params')\n",
    "# slim_loaded = load('./slim_best_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slim_loaded.beta, slim_loaded.lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pred_from_loaded = slim_loaded.predict(k=K,\n",
    "#     users=test.select('user_idx').distinct(),\n",
    "#     log=train,\n",
    "#     filter_seen_items=True)\n",
    "# pred_from_loaded.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# recs = indexer.inverse_transform(pred_from_loaded)\n",
    "# recs.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Other RePlay models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS\n",
    "Commonly-used matrix factorization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ItemKNN\n",
    "Commonly-used item-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(UserPopRec(), metrics, 'UserPopRec')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "recs = fit_predict_evaluate(ItemKNN(num_neighbours=100), metrics, 'ItemKNN')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(SLIM(seed=SEED), metrics, 'SLIM')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(Word2VecRec(seed=SEED), metrics, 'Word2VecRec')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(ADMMSLIM(seed=SEED), metrics, 'ADMM SLIM')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(ALSWrap(seed=SEED), metrics, 'Implicit ALS')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(ALSWrap(seed=SEED, implicit_prefs=False), metrics, 'Explicit ALS')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(PopRec(), metrics, 'PopRec')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(Wilson(), metrics, 'PopRec')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(RandomRec(seed=SEED, distribution='uniform'), metrics, 'RandomRec')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = fit_predict_evaluate(LightFMWrap(random_state=SEED), metrics, 'LightFM')\n",
    "metrics.results.sort_values('NDCG@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALSWrap, \n",
    "ADMMSLIM, \n",
    "ItemKNN,\n",
    "LightFMWrap, \n",
    "MultVAE, \n",
    "NeuroMF, \n",
    "SLIM, \n",
    "PopRec, \n",
    "RandomRec,\n",
    "UCB,\n",
    "UserPopRec,\n",
    "Wilson, \n",
    "Word2VecRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Compare RePlay models with others\n",
    "To easily evaluate recommendations obtained from other sources, read and pass these recommendations to ``Experiment``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.add_result(\"my_model\", recs.withColumn(\"relevance\", sf.rand()))\n",
    "# metrics.results.sort_values(\"NDCG@5\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "name": "movielens_nmf.ipynb",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "null"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
