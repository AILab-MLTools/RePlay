{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of the SASRec training and inference stages\n",
    "Note that all the given examples can be run without using PySpark, using only Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from replay.metrics import OfflineMetrics, Recall, Precision, MAP, NDCG, HitRate, MRR\n",
    "from replay.metrics.torch_metrics_builder import metrics_to_df\n",
    "from replay.splitters import LastNSplitter\n",
    "from replay.data import (\n",
    "    FeatureHint,\n",
    "    FeatureInfo,\n",
    "    FeatureSchema,\n",
    "    FeatureSource,\n",
    "    FeatureType,\n",
    "    Dataset,\n",
    ")\n",
    "from replay.models.nn.optimizer_utils import FatOptimizerFactory\n",
    "from replay.models.nn.sequential.callbacks import (\n",
    "    ValidationMetricsCallback,\n",
    "    SparkPredictionCallback,\n",
    "    PandasPredictionCallback, \n",
    "    TorchPredictionCallback,\n",
    "    QueryEmbeddingsPredictionCallback\n",
    ")\n",
    "from replay.models.nn.sequential.postprocessors import RemoveSeenItems\n",
    "from replay.data.nn import (\n",
    "    SequenceTokenizer,\n",
    "    SequentialDataset,\n",
    "    TensorFeatureSource,\n",
    "    TensorSchema,\n",
    "    TensorFeatureInfo\n",
    ")\n",
    "from replay.models.nn.sequential import SasRec\n",
    "from replay.models.nn.sequential.sasrec import (\n",
    "    SasRecPredictionDataset,\n",
    "    SasRecTrainingDataset,\n",
    "    SasRecValidationDataset,\n",
    "    SasRecPredictionBatch,\n",
    "    SasRecModel\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "### Load raw movielens-1M interactions, item features and user features.\n",
    "In the current implementation, the SASRec does not take into account the features of items or users. They are only used to get a complete list of users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rs-datasets in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (0.5.1)\n",
      "Requirement already satisfied: datatable in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (1.1.0)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (2.0.3)\n",
      "Requirement already satisfied: gdown in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (5.2.0)\n",
      "Requirement already satisfied: pyarrow in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (16.0.0)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (4.66.4)\n",
      "Requirement already satisfied: xlrd in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (2.0.1)\n",
      "Requirement already satisfied: kaggle in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (1.6.17)\n",
      "Requirement already satisfied: py7zr in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (0.22.0)\n",
      "Requirement already satisfied: openpyxl in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from rs-datasets) (3.1.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from gdown->rs-datasets) (4.12.3)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from gdown->rs-datasets) (3.14.0)\n",
      "Requirement already satisfied: requests[socks] in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from gdown->rs-datasets) (2.32.3)\n",
      "Requirement already satisfied: six>=1.10 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from kaggle->rs-datasets) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from kaggle->rs-datasets) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from kaggle->rs-datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from kaggle->rs-datasets) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from kaggle->rs-datasets) (2.2.1)\n",
      "Requirement already satisfied: bleach in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from kaggle->rs-datasets) (6.1.0)\n",
      "Requirement already satisfied: et-xmlfile in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from openpyxl->rs-datasets) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from pandas->rs-datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from pandas->rs-datasets) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from pandas->rs-datasets) (1.24.4)\n",
      "Requirement already satisfied: texttable in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (3.21.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (0.16.2)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (1.1.0)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (1.0.2)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (1.0.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (1.1.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from py7zr->rs-datasets) (6.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from beautifulsoup4->gdown->rs-datasets) (2.5)\n",
      "Requirement already satisfied: webencodings in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from bleach->kaggle->rs-datasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from python-slugify->kaggle->rs-datasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from requests[socks]->gdown->rs-datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from requests[socks]->gdown->rs-datasets) (3.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /root/miniconda3/envs/prp39/lib/python3.9/site-packages (from requests[socks]->gdown->rs-datasets) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rs-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rs_datasets import MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = MovieLens(\"1m\")\n",
    "interactions = movielens.ratings\n",
    "user_features = movielens.users\n",
    "item_features = movielens.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from replay.preprocessing.filters import NumInteractionsFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = NumInteractionsFilter(num_interactions=5).transform(interactions)\n",
    "sz = interactions.shape[0]\n",
    "cols = 8\n",
    "interactions[\"int_cat_list\"] = np.random.randint(0, 10, size=(sz, cols)).tolist()\n",
    "interactions[\"int_num_list\"] = np.random.randn(sz, cols).tolist()\n",
    "interactions[\"int_cat\"] = np.random.randint(0, 10, size=sz)\n",
    "interactions[\"int_num\"] = np.random.randn(sz)\n",
    "# interactions = pl.DataFrame(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>int_cat_list</th>\n",
       "      <th>int_num_list</th>\n",
       "      <th>int_cat</th>\n",
       "      <th>int_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>[8, 7, 2, 8, 8, 9, 3, 8]</td>\n",
       "      <td>[0.24572880036476222, -0.7152729663680886, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "      <td>[3, 2, 4, 1, 4, 1, 3, 4]</td>\n",
       "      <td>[-2.498021523672135, 1.734690788910874, 0.5201...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.280106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "      <td>[5, 4, 1, 8, 8, 8, 2, 6]</td>\n",
       "      <td>[-0.03397852975629857, -0.5360900145700243, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.040534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "      <td>[4, 1, 4, 5, 0, 0, 8, 6]</td>\n",
       "      <td>[-0.0028166290648475112, 0.35102236034715734, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.275206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>[9, 8, 9, 3, 0, 1, 0, 9]</td>\n",
       "      <td>[-0.9379731225884952, -0.6439550539955673, 0.9...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.627082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999873</th>\n",
       "      <td>6040</td>\n",
       "      <td>593</td>\n",
       "      <td>5</td>\n",
       "      <td>956703954</td>\n",
       "      <td>[2, 5, 3, 3, 2, 7, 4, 2]</td>\n",
       "      <td>[-1.4808639701602377, -1.8268327190500286, 0.4...</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.569295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000007</th>\n",
       "      <td>6040</td>\n",
       "      <td>1961</td>\n",
       "      <td>4</td>\n",
       "      <td>956703977</td>\n",
       "      <td>[2, 5, 3, 0, 8, 0, 4, 7]</td>\n",
       "      <td>[-0.4054356535467929, -1.7856277442760993, -0....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.434125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000138</th>\n",
       "      <td>6040</td>\n",
       "      <td>858</td>\n",
       "      <td>4</td>\n",
       "      <td>956703932</td>\n",
       "      <td>[4, 9, 9, 1, 8, 7, 9, 6]</td>\n",
       "      <td>[1.1419282800378616, 0.2226156482048346, -1.09...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.084541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000153</th>\n",
       "      <td>6040</td>\n",
       "      <td>2384</td>\n",
       "      <td>4</td>\n",
       "      <td>956703954</td>\n",
       "      <td>[1, 8, 2, 1, 4, 9, 3, 6]</td>\n",
       "      <td>[0.8937552446897207, 0.5148946738816954, 0.946...</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.246546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000192</th>\n",
       "      <td>6040</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>956703977</td>\n",
       "      <td>[5, 6, 1, 7, 8, 1, 5, 2]</td>\n",
       "      <td>[0.35081541878989636, -0.01370782993486719, -0...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.144655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating  timestamp              int_cat_list  \\\n",
       "22             1     1270       5  978300055  [8, 7, 2, 8, 8, 9, 3, 8]   \n",
       "24             1     2340       3  978300103  [3, 2, 4, 1, 4, 1, 3, 4]   \n",
       "27             1     1721       4  978300055  [5, 4, 1, 8, 8, 8, 2, 6]   \n",
       "31             1     3186       4  978300019  [4, 1, 4, 5, 0, 0, 8, 6]   \n",
       "37             1     1022       5  978300055  [9, 8, 9, 3, 0, 1, 0, 9]   \n",
       "...          ...      ...     ...        ...                       ...   \n",
       "999873      6040      593       5  956703954  [2, 5, 3, 3, 2, 7, 4, 2]   \n",
       "1000007     6040     1961       4  956703977  [2, 5, 3, 0, 8, 0, 4, 7]   \n",
       "1000138     6040      858       4  956703932  [4, 9, 9, 1, 8, 7, 9, 6]   \n",
       "1000153     6040     2384       4  956703954  [1, 8, 2, 1, 4, 9, 3, 6]   \n",
       "1000192     6040     2019       5  956703977  [5, 6, 1, 7, 8, 1, 5, 2]   \n",
       "\n",
       "                                              int_num_list  int_cat   int_num  \n",
       "22       [0.24572880036476222, -0.7152729663680886, 0.1...        0  0.440003  \n",
       "24       [-2.498021523672135, 1.734690788910874, 0.5201...        5  0.280106  \n",
       "27       [-0.03397852975629857, -0.5360900145700243, -0...        1 -1.040534  \n",
       "31       [-0.0028166290648475112, 0.35102236034715734, ...        5  1.275206  \n",
       "37       [-0.9379731225884952, -0.6439550539955673, 0.9...        3 -1.627082  \n",
       "...                                                    ...      ...       ...  \n",
       "999873   [-1.4808639701602377, -1.8268327190500286, 0.4...        9 -0.569295  \n",
       "1000007  [-0.4054356535467929, -1.7856277442760993, -0....        2  1.434125  \n",
       "1000138  [1.1419282800378616, 0.2226156482048346, -1.09...        2 -1.084541  \n",
       "1000153  [0.8937552446897207, 0.5148946738816954, 0.946...        5 -0.246546  \n",
       "1000192  [0.35081541878989636, -0.01370782993486719, -0...        8  0.144655  \n",
       "\n",
       "[30200 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>user_cat_list</th>\n",
       "      <th>user_num_list</th>\n",
       "      <th>user_cat</th>\n",
       "      <th>user_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[9, 3, 0, 3, 6, 3]</td>\n",
       "      <td>[1.2111897298669003, -0.7922902667218017, -0.9...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.997819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>[8, 3, 9, 2, 4, 2]</td>\n",
       "      <td>[0.18382585047496333, -0.7058809264180206, 1.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.371579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "      <td>[0, 9, 0, 6, 7, 3]</td>\n",
       "      <td>[0.795785306692731, -1.3811366620986492, -0.70...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.095353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "      <td>[9, 6, 9, 9, 2, 1]</td>\n",
       "      <td>[0.03285482950274071, -0.8895047563145416, -2....</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.527685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "      <td>[7, 4, 7, 7, 2, 6]</td>\n",
       "      <td>[-1.687836420724842, 1.2224750458654166, -0.39...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.859056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "      <td>[4, 5, 8, 8, 1, 7]</td>\n",
       "      <td>[-1.4000342842986702, 0.26085636617977365, 0.5...</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.796250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "      <td>[3, 1, 4, 1, 2, 4]</td>\n",
       "      <td>[0.09984811373233482, 0.19913765943789327, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.136610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "      <td>[4, 2, 5, 1, 7, 6]</td>\n",
       "      <td>[1.719147802279268, -0.09181037467022449, -0.1...</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.855963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "      <td>[0, 3, 5, 1, 4, 6]</td>\n",
       "      <td>[-0.359620324202194, -0.42374874936116047, -0....</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.546370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[8, 6, 4, 9, 3, 3]</td>\n",
       "      <td>[-2.0193503219280755, 0.13174207270107552, -0....</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.015310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id gender  age  occupation zip_code       user_cat_list  \\\n",
       "0           1      F    1          10    48067  [9, 3, 0, 3, 6, 3]   \n",
       "1           2      M   56          16    70072  [8, 3, 9, 2, 4, 2]   \n",
       "2           3      M   25          15    55117  [0, 9, 0, 6, 7, 3]   \n",
       "3           4      M   45           7    02460  [9, 6, 9, 9, 2, 1]   \n",
       "4           5      M   25          20    55455  [7, 4, 7, 7, 2, 6]   \n",
       "...       ...    ...  ...         ...      ...                 ...   \n",
       "6035     6036      F   25          15    32603  [4, 5, 8, 8, 1, 7]   \n",
       "6036     6037      F   45           1    76006  [3, 1, 4, 1, 2, 4]   \n",
       "6037     6038      F   56           1    14706  [4, 2, 5, 1, 7, 6]   \n",
       "6038     6039      F   45           0    01060  [0, 3, 5, 1, 4, 6]   \n",
       "6039     6040      M   25           6    11106  [8, 6, 4, 9, 3, 3]   \n",
       "\n",
       "                                          user_num_list  user_cat  user_num  \n",
       "0     [1.2111897298669003, -0.7922902667218017, -0.9...         0  1.997819  \n",
       "1     [0.18382585047496333, -0.7058809264180206, 1.0...         0 -0.371579  \n",
       "2     [0.795785306692731, -1.3811366620986492, -0.70...         3  1.095353  \n",
       "3     [0.03285482950274071, -0.8895047563145416, -2....         5 -1.527685  \n",
       "4     [-1.687836420724842, 1.2224750458654166, -0.39...         2 -1.859056  \n",
       "...                                                 ...       ...       ...  \n",
       "6035  [-1.4000342842986702, 0.26085636617977365, 0.5...         5 -0.796250  \n",
       "6036  [0.09984811373233482, 0.19913765943789327, -0....         0 -0.136610  \n",
       "6037  [1.719147802279268, -0.09181037467022449, -0.1...         6 -0.855963  \n",
       "6038  [-0.359620324202194, -0.42374874936116047, -0....         4 -0.546370  \n",
       "6039  [-2.0193503219280755, 0.13174207270107552, -0....         8 -1.015310  \n",
       "\n",
       "[6040 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = user_features.shape[0]\n",
    "cols = 6\n",
    "user_features[\"user_cat_list\"] = np.random.randint(0, 10, size=(sz, cols)).tolist()\n",
    "user_features[\"user_num_list\"] = np.random.randn(sz, cols).tolist()\n",
    "user_features[\"user_cat\"] = np.random.randint(0, 10, size=sz)\n",
    "user_features[\"user_num\"] = np.random.randn(sz)\n",
    "# user_features = pl.DataFrame(user_features)\n",
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>item_cat_list</th>\n",
       "      <th>item_num_list</th>\n",
       "      <th>item_cat</th>\n",
       "      <th>item_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Animation, Children's, Comedy]</td>\n",
       "      <td>[1, 2, 9, 7, 0, 8, 5, 7, 1, 9, 0, 0, 0]</td>\n",
       "      <td>[1.483023156832867, 0.2017158849271806, -1.072...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.100583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[Adventure, Children's, Fantasy]</td>\n",
       "      <td>[4, 1, 8, 3, 8, 7, 2, 6, 6, 2, 3, 3, 3]</td>\n",
       "      <td>[0.5782075484621079, -0.21321734323060212, 1.3...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.175274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>[9, 2, 4, 6, 5, 0, 6, 8, 1, 1, 4, 4, 2]</td>\n",
       "      <td>[-1.1167608107588163, -0.41245990294713114, 0....</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.155622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>[9, 7, 1, 2, 5, 6, 1, 3, 5, 3, 1, 2, 5]</td>\n",
       "      <td>[0.4794109226302443, -1.092724901461659, -0.35...</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.466517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>[4, 1, 9, 6, 1, 8, 6, 4, 8, 7, 5, 9, 1]</td>\n",
       "      <td>[-0.9490019410443985, -0.09912696671171735, -0...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.352423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>[9, 3, 0, 2, 5, 2, 4, 1, 3, 2, 5, 2, 7]</td>\n",
       "      <td>[-0.12663426919750576, -1.1929886761016977, 0....</td>\n",
       "      <td>7</td>\n",
       "      <td>0.377766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[1, 1, 9, 7, 0, 8, 7, 0, 1, 5, 4, 8, 1]</td>\n",
       "      <td>[-0.9899699214818928, 0.7804655494279595, 0.41...</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.656263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[8, 2, 4, 0, 5, 4, 1, 3, 7, 0, 9, 2, 4]</td>\n",
       "      <td>[0.009821626086104252, -1.379736875660516, -0....</td>\n",
       "      <td>5</td>\n",
       "      <td>1.077170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[7, 1, 6, 6, 6, 3, 0, 5, 9, 6, 6, 1, 7]</td>\n",
       "      <td>[0.3219107308272653, 0.41538625133745893, -0.4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>[Drama, Thriller]</td>\n",
       "      <td>[2, 7, 6, 3, 3, 2, 5, 4, 8, 4, 0, 1, 0]</td>\n",
       "      <td>[-1.9681830680061732, -1.3184447851672527, 0.6...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.120308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                               title  \\\n",
       "0           1                    Toy Story (1995)   \n",
       "1           2                      Jumanji (1995)   \n",
       "2           3             Grumpier Old Men (1995)   \n",
       "3           4            Waiting to Exhale (1995)   \n",
       "4           5  Father of the Bride Part II (1995)   \n",
       "...       ...                                 ...   \n",
       "3878     3948             Meet the Parents (2000)   \n",
       "3879     3949          Requiem for a Dream (2000)   \n",
       "3880     3950                    Tigerland (2000)   \n",
       "3881     3951             Two Family House (2000)   \n",
       "3882     3952               Contender, The (2000)   \n",
       "\n",
       "                                genres  \\\n",
       "0      [Animation, Children's, Comedy]   \n",
       "1     [Adventure, Children's, Fantasy]   \n",
       "2                    [Comedy, Romance]   \n",
       "3                      [Comedy, Drama]   \n",
       "4                             [Comedy]   \n",
       "...                                ...   \n",
       "3878                          [Comedy]   \n",
       "3879                           [Drama]   \n",
       "3880                           [Drama]   \n",
       "3881                           [Drama]   \n",
       "3882                 [Drama, Thriller]   \n",
       "\n",
       "                                item_cat_list  \\\n",
       "0     [1, 2, 9, 7, 0, 8, 5, 7, 1, 9, 0, 0, 0]   \n",
       "1     [4, 1, 8, 3, 8, 7, 2, 6, 6, 2, 3, 3, 3]   \n",
       "2     [9, 2, 4, 6, 5, 0, 6, 8, 1, 1, 4, 4, 2]   \n",
       "3     [9, 7, 1, 2, 5, 6, 1, 3, 5, 3, 1, 2, 5]   \n",
       "4     [4, 1, 9, 6, 1, 8, 6, 4, 8, 7, 5, 9, 1]   \n",
       "...                                       ...   \n",
       "3878  [9, 3, 0, 2, 5, 2, 4, 1, 3, 2, 5, 2, 7]   \n",
       "3879  [1, 1, 9, 7, 0, 8, 7, 0, 1, 5, 4, 8, 1]   \n",
       "3880  [8, 2, 4, 0, 5, 4, 1, 3, 7, 0, 9, 2, 4]   \n",
       "3881  [7, 1, 6, 6, 6, 3, 0, 5, 9, 6, 6, 1, 7]   \n",
       "3882  [2, 7, 6, 3, 3, 2, 5, 4, 8, 4, 0, 1, 0]   \n",
       "\n",
       "                                          item_num_list  item_cat  item_num  \n",
       "0     [1.483023156832867, 0.2017158849271806, -1.072...         9  0.100583  \n",
       "1     [0.5782075484621079, -0.21321734323060212, 1.3...         3  1.175274  \n",
       "2     [-1.1167608107588163, -0.41245990294713114, 0....         4 -0.155622  \n",
       "3     [0.4794109226302443, -1.092724901461659, -0.35...         4 -0.466517  \n",
       "4     [-0.9490019410443985, -0.09912696671171735, -0...         5  1.352423  \n",
       "...                                                 ...       ...       ...  \n",
       "3878  [-0.12663426919750576, -1.1929886761016977, 0....         7  0.377766  \n",
       "3879  [-0.9899699214818928, 0.7804655494279595, 0.41...         4 -0.656263  \n",
       "3880  [0.009821626086104252, -1.379736875660516, -0....         5  1.077170  \n",
       "3881  [0.3219107308272653, 0.41538625133745893, -0.4...         0  0.436232  \n",
       "3882  [-1.9681830680061732, -1.3184447851672527, 0.6...         0 -1.120308  \n",
       "\n",
       "[3883 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = item_features.shape[0]\n",
    "cols = 13\n",
    "item_features.sort_values(\"item_id\", inplace=True)\n",
    "item_features[\"item_cat_list\"] = np.random.randint(0, 10, size=(sz, cols)).tolist()\n",
    "item_features[\"item_num_list\"] = np.random.randn(sz, cols).tolist()\n",
    "item_features[\"item_cat\"] = np.random.randint(0, 10, size=sz).tolist()\n",
    "item_features[\"item_num\"] = np.random.randn(sz).tolist()\n",
    "item_features[\"genres\"] = item_features[\"genres\"].str.split('|')\n",
    "# item_features = pl.DataFrame(item_features)\n",
    "item_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing duplicates in the timestamp column without changing the original items order where timestamp is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions[\"timestamp\"] = interactions[\"timestamp\"].astype(\"int64\")\n",
    "# interactions = interactions.sort_values(by=\"timestamp\")\n",
    "# interactions[\"timestamp\"] = interactions.groupby(\"user_id\").cumcount()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split interactions into the train, validation and test datasets using LastNSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = LastNSplitter(\n",
    "    N=1,\n",
    "    divide_column=\"user_id\",\n",
    "    query_column=\"user_id\",\n",
    "    strategy=\"interactions\",\n",
    ")\n",
    "\n",
    "raw_test_events, raw_test_gt = splitter.split(interactions)\n",
    "raw_validation_events, raw_validation_gt = splitter.split(raw_test_events)\n",
    "raw_train_events = raw_validation_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare FeatureSchema required to create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_feature_schema(is_ground_truth: bool) -> FeatureSchema:\n",
    "    all_features = FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"user_id\",\n",
    "                feature_hint=FeatureHint.QUERY_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"item_id\",\n",
    "                feature_hint=FeatureHint.ITEM_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"int_cat_list\",\n",
    "                feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"int_num_list\",\n",
    "                feature_type=FeatureType.NUMERICAL_LIST,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"int_cat\",\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"int_num\",\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    if is_ground_truth:\n",
    "        return all_features\n",
    "\n",
    "    all_features = all_features + FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"timestamp\",\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "                feature_hint=FeatureHint.TIMESTAMP,\n",
    "            ),\n",
    "            # item features\n",
    "            FeatureInfo(\n",
    "                column=\"item_cat_list\",\n",
    "                feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "                feature_source=FeatureSource.ITEM_FEATURES,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"genres\",\n",
    "                feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "                feature_source=FeatureSource.ITEM_FEATURES,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"item_num_list\",\n",
    "                feature_type=FeatureType.NUMERICAL_LIST,\n",
    "                feature_source=FeatureSource.ITEM_FEATURES,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"item_cat\",\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "                feature_source=FeatureSource.ITEM_FEATURES,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"item_num\",\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "                feature_source=FeatureSource.ITEM_FEATURES,\n",
    "            ),\n",
    "            # query features\n",
    "            FeatureInfo(\n",
    "                column=\"user_cat_list\",\n",
    "                feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "                feature_source=FeatureSource.QUERY_FEATURES,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"user_num_list\",\n",
    "                feature_type=FeatureType.NUMERICAL_LIST,\n",
    "                feature_source=FeatureSource.QUERY_FEATURES,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"user_cat\",\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "                feature_source=FeatureSource.QUERY_FEATURES,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"user_num\",\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "                feature_source=FeatureSource.QUERY_FEATURES,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return all_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset for the training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_train_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets (events and ground_truth) for the validation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_validation_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=raw_validation_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets (events and ground_truth) for the testing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_test_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=raw_test_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the tensor schema\n",
    "A schema shows the correspondence of columns from the source dataset with the internal representation of tensors inside the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_FEATURE_NAME = \"item_id_seq\"\n",
    "\n",
    "tensor_schema = TensorSchema([\n",
    "    TensorFeatureInfo(\n",
    "        name=ITEM_FEATURE_NAME,\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.INTERACTIONS, train_dataset.feature_schema.item_id_column),\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"timestamp_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.NUMERICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.INTERACTIONS, \"timestamp\"),\n",
    "        feature_hint=FeatureHint.TIMESTAMP,\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"item_cat_list_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"item_cat_list\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"genres_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"genres\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"item_num_list_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.NUMERICAL_LIST,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"item_num_list\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"item_cat_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"item_cat\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"item_num_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.NUMERICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"item_num\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"int_cat_list_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.INTERACTIONS, \"int_cat_list\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"int_num_list_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.NUMERICAL_LIST,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.INTERACTIONS, \"int_num_list\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"int_cat_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.INTERACTIONS, \"int_cat\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"int_num_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.NUMERICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.INTERACTIONS, \"int_num\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"user_cat_list_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.QUERY_FEATURES, \"user_cat_list\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"user_cat_list_not_seq\",\n",
    "        is_seq=False,\n",
    "        feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.QUERY_FEATURES, \"user_cat_list\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"user_cat_seq\",\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.QUERY_FEATURES, \"user_cat\"),\n",
    "    ),\n",
    "    TensorFeatureInfo(\n",
    "        name=\"user_cat_not_seq\",\n",
    "        is_seq=False,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_source=TensorFeatureSource(FeatureSource.QUERY_FEATURES, \"user_cat\"),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequential datasets using SequenceTokenizer\n",
    "The SequentialDataset internally store data in the form of sequences of items sorted by increasing interaction time (timestamp). A SequenceTokenizer is used to convert to this format. In addition, the SequenceTokenizer encodes all categorical columns from the source dataset and stores mapping inside itself.\n",
    "SequentialDataset.keep_common_query_ids is used to leave only sequences from the same users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset)\n",
    "\n",
    "sequential_train_dataset = tokenizer.transform(train_dataset)\n",
    "\n",
    "sequential_validation_dataset = tokenizer.transform(validation_dataset)\n",
    "sequential_validation_gt = tokenizer.transform(validation_gt, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_validation_dataset, sequential_validation_gt = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_validation_dataset, sequential_validation_gt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id_seq</th>\n",
       "      <th>timestamp_seq</th>\n",
       "      <th>item_cat_list_seq</th>\n",
       "      <th>genres_seq</th>\n",
       "      <th>item_num_list_seq</th>\n",
       "      <th>item_cat_seq</th>\n",
       "      <th>item_num_seq</th>\n",
       "      <th>int_cat_list_seq</th>\n",
       "      <th>int_num_list_seq</th>\n",
       "      <th>int_cat_seq</th>\n",
       "      <th>int_num_seq</th>\n",
       "      <th>user_cat_list_seq</th>\n",
       "      <th>user_cat_list_not_seq</th>\n",
       "      <th>user_cat_seq</th>\n",
       "      <th>user_cat_not_seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3117, 1672, 1250]</td>\n",
       "      <td>[978300019, 978300055, 978300055]</td>\n",
       "      <td>[[5, 0, 4, 9, 9, 5, 7, 7, 3, 7, 8, 2, 1], [2, ...</td>\n",
       "      <td>[[6], [6, 5], [2, 11]]</td>\n",
       "      <td>[[-0.7371095169935106, 0.5172784209909229, -1....</td>\n",
       "      <td>[9, 4, 5]</td>\n",
       "      <td>[[0.3400542192326083], [-0.5327000480128626], ...</td>\n",
       "      <td>[[0, 1, 0, 2, 3, 3, 4, 5], [2, 0, 1, 4, 4, 4, ...</td>\n",
       "      <td>[[-0.0028166290648475112, 0.35102236034715734,...</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>[[1.2752063911674782], [-1.040534072536861], [...</td>\n",
       "      <td>[[0, 1, 2, 1, 3, 1], [0, 1, 2, 1, 3, 1], [0, 1...</td>\n",
       "      <td>[0, 1, 2, 1, 3, 1]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1180, 1199, 1192]</td>\n",
       "      <td>[978298124, 978298151, 978298151]</td>\n",
       "      <td>[[5, 2, 8, 5, 5, 6, 1, 5, 7, 5, 9, 6, 5], [0, ...</td>\n",
       "      <td>[[7, 3], [6, 13], [7, 3, 5, 11, 13]]</td>\n",
       "      <td>[[-0.6719777117797717, -0.15292580017366167, -...</td>\n",
       "      <td>[4, 5, 5]</td>\n",
       "      <td>[[0.07143264876231152], [0.2492790165508092], ...</td>\n",
       "      <td>[[7, 8, 4, 5, 2, 1, 3, 5], [4, 8, 6, 4, 0, 9, ...</td>\n",
       "      <td>[[0.021013318399510088, 0.649640590328758, -0....</td>\n",
       "      <td>[3, 4, 4]</td>\n",
       "      <td>[[1.0805619729097102], [-0.7668057972668736], ...</td>\n",
       "      <td>[[4, 1, 0, 5, 6, 5], [4, 1, 0, 5, 6, 5], [4, 1...</td>\n",
       "      <td>[4, 1, 0, 5, 6, 5]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[589, 2789, 3465]</td>\n",
       "      <td>[978297018, 978297039, 978297068]</td>\n",
       "      <td>[[3, 8, 0, 5, 0, 1, 5, 1, 9, 5, 0, 9, 9], [4, ...</td>\n",
       "      <td>[[6, 9], [2, 6], [2]]</td>\n",
       "      <td>[[0.08949539369713089, 1.4161395609414833, 1.3...</td>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>[[-0.683346597120824], [-0.831939087874874], [...</td>\n",
       "      <td>[[4, 0, 7, 6, 9, 0, 7, 3], [2, 8, 8, 0, 7, 1, ...</td>\n",
       "      <td>[[-0.7979330310055955, 0.01904892113566897, 0....</td>\n",
       "      <td>[5, 3, 5]</td>\n",
       "      <td>[[-0.9717097665967962], [-0.29187845503131743]...</td>\n",
       "      <td>[[2, 0, 2, 3, 7, 1], [2, 0, 2, 3, 7, 1], [2, 0...</td>\n",
       "      <td>[2, 0, 2, 3, 7, 1]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1192, 1081, 3399]</td>\n",
       "      <td>[978293924, 978293964, 978294008]</td>\n",
       "      <td>[[6, 6, 1, 8, 2, 0, 7, 1, 0, 4, 1, 0, 9], [2, ...</td>\n",
       "      <td>[[7, 3, 5, 11, 13], [1, 6, 4, 11], [6]]</td>\n",
       "      <td>[[-0.2387270365605642, -0.8439073598335783, -0...</td>\n",
       "      <td>[5, 5, 0]</td>\n",
       "      <td>[[0.9397320452383293], [0.33043226126353237], ...</td>\n",
       "      <td>[[1, 4, 6, 6, 0, 2, 6, 9], [3, 4, 4, 9, 3, 3, ...</td>\n",
       "      <td>[[1.2986729199803495, -1.1270799714320086, -0....</td>\n",
       "      <td>[4, 6, 3]</td>\n",
       "      <td>[[-0.6018698159177285], [0.24092595217721435],...</td>\n",
       "      <td>[[0, 3, 0, 0, 5, 8], [0, 3, 0, 0, 5, 8], [0, 3...</td>\n",
       "      <td>[0, 3, 0, 0, 5, 8]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[896, 907, 2648]</td>\n",
       "      <td>[978241072, 978241072, 978241072]</td>\n",
       "      <td>[[0, 0, 6, 5, 5, 2, 9, 9, 8, 8, 2, 7, 9], [2, ...</td>\n",
       "      <td>[[6, 9], [3, 1, 6, 14], [2, 10]]</td>\n",
       "      <td>[[-1.5867769587025542, -1.0325545345483913, 0....</td>\n",
       "      <td>[5, 0, 2]</td>\n",
       "      <td>[[1.4447708685088008], [-0.5718358307077351], ...</td>\n",
       "      <td>[[4, 1, 0, 7, 6, 2, 9, 1], [8, 5, 6, 3, 6, 6, ...</td>\n",
       "      <td>[[1.0751836701583652, -0.209538781476585, 0.19...</td>\n",
       "      <td>[7, 3, 3]</td>\n",
       "      <td>[[-1.2840729543035985], [-0.7620753702928027],...</td>\n",
       "      <td>[[7, 6, 7, 7, 5, 3], [7, 6, 7, 7, 5, 3], [7, 6...</td>\n",
       "      <td>[7, 6, 7, 7, 5, 3]</td>\n",
       "      <td>[3, 3, 3]</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>[1672, 3369, 2359]</td>\n",
       "      <td>[956709349, 956709350, 956709350]</td>\n",
       "      <td>[[2, 3, 4, 1, 0, 7, 1, 2, 3, 8, 1, 4, 8], [6, ...</td>\n",
       "      <td>[[6, 5], [7, 1, 4], [10, 11]]</td>\n",
       "      <td>[[-1.646148393952946, 0.1432692730406104, -1.8...</td>\n",
       "      <td>[4, 9, 7]</td>\n",
       "      <td>[[-0.5327000480128626], [1.0244708036566967], ...</td>\n",
       "      <td>[[1, 2, 4, 9, 2, 1, 4, 2], [6, 1, 7, 6, 9, 3, ...</td>\n",
       "      <td>[[1.52817633451984, -0.07949328621943147, -0.5...</td>\n",
       "      <td>[0, 3, 2]</td>\n",
       "      <td>[[-1.9064846359939154], [-0.34495441787373565]...</td>\n",
       "      <td>[[6, 9, 4, 4, 8, 7], [6, 9, 4, 4, 8, 7], [6, 9...</td>\n",
       "      <td>[6, 9, 4, 4, 8, 7]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>[1813, 693, 3439]</td>\n",
       "      <td>[956708997, 956708997, 956708997]</td>\n",
       "      <td>[[8, 6, 4, 1, 9, 7, 5, 0, 5, 3, 8, 4, 9], [1, ...</td>\n",
       "      <td>[[7, 11], [6], [17]]</td>\n",
       "      <td>[[-0.36946844520740235, -1.6465738035656168, -...</td>\n",
       "      <td>[6, 9, 7]</td>\n",
       "      <td>[[0.780361891121729], [-0.290044401792015], [0...</td>\n",
       "      <td>[[0, 6, 9, 1, 0, 8, 6, 8], [8, 3, 1, 3, 2, 3, ...</td>\n",
       "      <td>[[-0.0763071077550825, -0.4373363711879449, 2....</td>\n",
       "      <td>[0, 0, 6]</td>\n",
       "      <td>[[-1.3163328783677797], [-1.2103231865302504],...</td>\n",
       "      <td>[[1, 8, 6, 8, 5, 6], [1, 8, 6, 8, 5, 6], [1, 8...</td>\n",
       "      <td>[1, 8, 6, 8, 5, 6]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>[908, 3327, 1192]</td>\n",
       "      <td>[956706827, 956706827, 956706876]</td>\n",
       "      <td>[[1, 5, 7, 7, 1, 0, 2, 5, 0, 2, 1, 6, 9], [3, ...</td>\n",
       "      <td>[[6, 5, 13], [1, 2], [7, 3, 5, 11, 13]]</td>\n",
       "      <td>[[0.3065607516434541, 1.3960166413808077, -0.8...</td>\n",
       "      <td>[9, 5, 5]</td>\n",
       "      <td>[[-0.5479268740237664], [-1.4583412706046626],...</td>\n",
       "      <td>[[5, 7, 6, 9, 4, 2, 6, 1], [9, 8, 4, 6, 0, 1, ...</td>\n",
       "      <td>[[1.0105654096715015, -1.018890145563342, -1.7...</td>\n",
       "      <td>[2, 5, 4]</td>\n",
       "      <td>[[-0.6949371998265383], [0.5861496479174915], ...</td>\n",
       "      <td>[[6, 5, 9, 8, 7, 3], [6, 5, 9, 8, 7, 3], [6, 5...</td>\n",
       "      <td>[6, 5, 9, 8, 7, 3]</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>[109, 279, 1998]</td>\n",
       "      <td>[956705158, 956705158, 956705178]</td>\n",
       "      <td>[[5, 5, 8, 5, 8, 7, 6, 3, 1, 3, 2, 3, 0], [7, ...</td>\n",
       "      <td>[[6, 9], [6], [6, 5, 13]]</td>\n",
       "      <td>[[1.0218728809923543, 1.0196736846023107, 0.63...</td>\n",
       "      <td>[1, 0, 5]</td>\n",
       "      <td>[[-0.3182419807525344], [0.5984158545174856], ...</td>\n",
       "      <td>[[6, 7, 6, 1, 9, 4, 3, 4], [6, 8, 5, 9, 5, 3, ...</td>\n",
       "      <td>[[0.27472251690331195, 0.30800934472732383, -0...</td>\n",
       "      <td>[1, 5, 5]</td>\n",
       "      <td>[[-0.7812099122988537], [-0.2478627138267907],...</td>\n",
       "      <td>[[2, 1, 9, 8, 6, 3], [2, 1, 9, 8, 6, 3], [2, 1...</td>\n",
       "      <td>[2, 1, 9, 8, 6, 3]</td>\n",
       "      <td>[8, 8, 8]</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>[847, 589, 2315]</td>\n",
       "      <td>[956703932, 956703954, 956703954]</td>\n",
       "      <td>[[0, 2, 7, 8, 5, 4, 8, 9, 5, 9, 8, 2, 4], [3, ...</td>\n",
       "      <td>[[7, 8, 6], [6, 9], [1, 2]]</td>\n",
       "      <td>[[-0.1466413721617946, 1.139981244700704, -0.1...</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[[1.5968322325999589], [-0.683346597120824], [...</td>\n",
       "      <td>[[0, 8, 8, 1, 4, 6, 8, 5], [7, 2, 9, 9, 7, 6, ...</td>\n",
       "      <td>[[1.1419282800378616, 0.2226156482048346, -1.0...</td>\n",
       "      <td>[7, 4, 0]</td>\n",
       "      <td>[[-1.0845405993732244], [-0.5692952997573383],...</td>\n",
       "      <td>[[4, 3, 6, 0, 1, 1], [4, 3, 6, 0, 1, 1], [4, 3...</td>\n",
       "      <td>[4, 3, 6, 0, 1, 1]</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                item_id_seq                      timestamp_seq  \\\n",
       "user_id                                                          \n",
       "0        [3117, 1672, 1250]  [978300019, 978300055, 978300055]   \n",
       "1        [1180, 1199, 1192]  [978298124, 978298151, 978298151]   \n",
       "2         [589, 2789, 3465]  [978297018, 978297039, 978297068]   \n",
       "3        [1192, 1081, 3399]  [978293924, 978293964, 978294008]   \n",
       "4          [896, 907, 2648]  [978241072, 978241072, 978241072]   \n",
       "...                     ...                                ...   \n",
       "6035     [1672, 3369, 2359]  [956709349, 956709350, 956709350]   \n",
       "6036      [1813, 693, 3439]  [956708997, 956708997, 956708997]   \n",
       "6037      [908, 3327, 1192]  [956706827, 956706827, 956706876]   \n",
       "6038       [109, 279, 1998]  [956705158, 956705158, 956705178]   \n",
       "6039       [847, 589, 2315]  [956703932, 956703954, 956703954]   \n",
       "\n",
       "                                         item_cat_list_seq  \\\n",
       "user_id                                                      \n",
       "0        [[5, 0, 4, 9, 9, 5, 7, 7, 3, 7, 8, 2, 1], [2, ...   \n",
       "1        [[5, 2, 8, 5, 5, 6, 1, 5, 7, 5, 9, 6, 5], [0, ...   \n",
       "2        [[3, 8, 0, 5, 0, 1, 5, 1, 9, 5, 0, 9, 9], [4, ...   \n",
       "3        [[6, 6, 1, 8, 2, 0, 7, 1, 0, 4, 1, 0, 9], [2, ...   \n",
       "4        [[0, 0, 6, 5, 5, 2, 9, 9, 8, 8, 2, 7, 9], [2, ...   \n",
       "...                                                    ...   \n",
       "6035     [[2, 3, 4, 1, 0, 7, 1, 2, 3, 8, 1, 4, 8], [6, ...   \n",
       "6036     [[8, 6, 4, 1, 9, 7, 5, 0, 5, 3, 8, 4, 9], [1, ...   \n",
       "6037     [[1, 5, 7, 7, 1, 0, 2, 5, 0, 2, 1, 6, 9], [3, ...   \n",
       "6038     [[5, 5, 8, 5, 8, 7, 6, 3, 1, 3, 2, 3, 0], [7, ...   \n",
       "6039     [[0, 2, 7, 8, 5, 4, 8, 9, 5, 9, 8, 2, 4], [3, ...   \n",
       "\n",
       "                                      genres_seq  \\\n",
       "user_id                                            \n",
       "0                         [[6], [6, 5], [2, 11]]   \n",
       "1           [[7, 3], [6, 13], [7, 3, 5, 11, 13]]   \n",
       "2                          [[6, 9], [2, 6], [2]]   \n",
       "3        [[7, 3, 5, 11, 13], [1, 6, 4, 11], [6]]   \n",
       "4               [[6, 9], [3, 1, 6, 14], [2, 10]]   \n",
       "...                                          ...   \n",
       "6035               [[6, 5], [7, 1, 4], [10, 11]]   \n",
       "6036                        [[7, 11], [6], [17]]   \n",
       "6037     [[6, 5, 13], [1, 2], [7, 3, 5, 11, 13]]   \n",
       "6038                   [[6, 9], [6], [6, 5, 13]]   \n",
       "6039                 [[7, 8, 6], [6, 9], [1, 2]]   \n",
       "\n",
       "                                         item_num_list_seq item_cat_seq  \\\n",
       "user_id                                                                   \n",
       "0        [[-0.7371095169935106, 0.5172784209909229, -1....    [9, 4, 5]   \n",
       "1        [[-0.6719777117797717, -0.15292580017366167, -...    [4, 5, 5]   \n",
       "2        [[0.08949539369713089, 1.4161395609414833, 1.3...    [4, 5, 6]   \n",
       "3        [[-0.2387270365605642, -0.8439073598335783, -0...    [5, 5, 0]   \n",
       "4        [[-1.5867769587025542, -1.0325545345483913, 0....    [5, 0, 2]   \n",
       "...                                                    ...          ...   \n",
       "6035     [[-1.646148393952946, 0.1432692730406104, -1.8...    [4, 9, 7]   \n",
       "6036     [[-0.36946844520740235, -1.6465738035656168, -...    [6, 9, 7]   \n",
       "6037     [[0.3065607516434541, 1.3960166413808077, -0.8...    [9, 5, 5]   \n",
       "6038     [[1.0218728809923543, 1.0196736846023107, 0.63...    [1, 0, 5]   \n",
       "6039     [[-0.1466413721617946, 1.139981244700704, -0.1...    [6, 4, 5]   \n",
       "\n",
       "                                              item_num_seq  \\\n",
       "user_id                                                      \n",
       "0        [[0.3400542192326083], [-0.5327000480128626], ...   \n",
       "1        [[0.07143264876231152], [0.2492790165508092], ...   \n",
       "2        [[-0.683346597120824], [-0.831939087874874], [...   \n",
       "3        [[0.9397320452383293], [0.33043226126353237], ...   \n",
       "4        [[1.4447708685088008], [-0.5718358307077351], ...   \n",
       "...                                                    ...   \n",
       "6035     [[-0.5327000480128626], [1.0244708036566967], ...   \n",
       "6036     [[0.780361891121729], [-0.290044401792015], [0...   \n",
       "6037     [[-0.5479268740237664], [-1.4583412706046626],...   \n",
       "6038     [[-0.3182419807525344], [0.5984158545174856], ...   \n",
       "6039     [[1.5968322325999589], [-0.683346597120824], [...   \n",
       "\n",
       "                                          int_cat_list_seq  \\\n",
       "user_id                                                      \n",
       "0        [[0, 1, 0, 2, 3, 3, 4, 5], [2, 0, 1, 4, 4, 4, ...   \n",
       "1        [[7, 8, 4, 5, 2, 1, 3, 5], [4, 8, 6, 4, 0, 9, ...   \n",
       "2        [[4, 0, 7, 6, 9, 0, 7, 3], [2, 8, 8, 0, 7, 1, ...   \n",
       "3        [[1, 4, 6, 6, 0, 2, 6, 9], [3, 4, 4, 9, 3, 3, ...   \n",
       "4        [[4, 1, 0, 7, 6, 2, 9, 1], [8, 5, 6, 3, 6, 6, ...   \n",
       "...                                                    ...   \n",
       "6035     [[1, 2, 4, 9, 2, 1, 4, 2], [6, 1, 7, 6, 9, 3, ...   \n",
       "6036     [[0, 6, 9, 1, 0, 8, 6, 8], [8, 3, 1, 3, 2, 3, ...   \n",
       "6037     [[5, 7, 6, 9, 4, 2, 6, 1], [9, 8, 4, 6, 0, 1, ...   \n",
       "6038     [[6, 7, 6, 1, 9, 4, 3, 4], [6, 8, 5, 9, 5, 3, ...   \n",
       "6039     [[0, 8, 8, 1, 4, 6, 8, 5], [7, 2, 9, 9, 7, 6, ...   \n",
       "\n",
       "                                          int_num_list_seq int_cat_seq  \\\n",
       "user_id                                                                  \n",
       "0        [[-0.0028166290648475112, 0.35102236034715734,...   [0, 2, 1]   \n",
       "1        [[0.021013318399510088, 0.649640590328758, -0....   [3, 4, 4]   \n",
       "2        [[-0.7979330310055955, 0.01904892113566897, 0....   [5, 3, 5]   \n",
       "3        [[1.2986729199803495, -1.1270799714320086, -0....   [4, 6, 3]   \n",
       "4        [[1.0751836701583652, -0.209538781476585, 0.19...   [7, 3, 3]   \n",
       "...                                                    ...         ...   \n",
       "6035     [[1.52817633451984, -0.07949328621943147, -0.5...   [0, 3, 2]   \n",
       "6036     [[-0.0763071077550825, -0.4373363711879449, 2....   [0, 0, 6]   \n",
       "6037     [[1.0105654096715015, -1.018890145563342, -1.7...   [2, 5, 4]   \n",
       "6038     [[0.27472251690331195, 0.30800934472732383, -0...   [1, 5, 5]   \n",
       "6039     [[1.1419282800378616, 0.2226156482048346, -1.0...   [7, 4, 0]   \n",
       "\n",
       "                                               int_num_seq  \\\n",
       "user_id                                                      \n",
       "0        [[1.2752063911674782], [-1.040534072536861], [...   \n",
       "1        [[1.0805619729097102], [-0.7668057972668736], ...   \n",
       "2        [[-0.9717097665967962], [-0.29187845503131743]...   \n",
       "3        [[-0.6018698159177285], [0.24092595217721435],...   \n",
       "4        [[-1.2840729543035985], [-0.7620753702928027],...   \n",
       "...                                                    ...   \n",
       "6035     [[-1.9064846359939154], [-0.34495441787373565]...   \n",
       "6036     [[-1.3163328783677797], [-1.2103231865302504],...   \n",
       "6037     [[-0.6949371998265383], [0.5861496479174915], ...   \n",
       "6038     [[-0.7812099122988537], [-0.2478627138267907],...   \n",
       "6039     [[-1.0845405993732244], [-0.5692952997573383],...   \n",
       "\n",
       "                                         user_cat_list_seq  \\\n",
       "user_id                                                      \n",
       "0        [[0, 1, 2, 1, 3, 1], [0, 1, 2, 1, 3, 1], [0, 1...   \n",
       "1        [[4, 1, 0, 5, 6, 5], [4, 1, 0, 5, 6, 5], [4, 1...   \n",
       "2        [[2, 0, 2, 3, 7, 1], [2, 0, 2, 3, 7, 1], [2, 0...   \n",
       "3        [[0, 3, 0, 0, 5, 8], [0, 3, 0, 0, 5, 8], [0, 3...   \n",
       "4        [[7, 6, 7, 7, 5, 3], [7, 6, 7, 7, 5, 3], [7, 6...   \n",
       "...                                                    ...   \n",
       "6035     [[6, 9, 4, 4, 8, 7], [6, 9, 4, 4, 8, 7], [6, 9...   \n",
       "6036     [[1, 8, 6, 8, 5, 6], [1, 8, 6, 8, 5, 6], [1, 8...   \n",
       "6037     [[6, 5, 9, 8, 7, 3], [6, 5, 9, 8, 7, 3], [6, 5...   \n",
       "6038     [[2, 1, 9, 8, 6, 3], [2, 1, 9, 8, 6, 3], [2, 1...   \n",
       "6039     [[4, 3, 6, 0, 1, 1], [4, 3, 6, 0, 1, 1], [4, 3...   \n",
       "\n",
       "        user_cat_list_not_seq user_cat_seq user_cat_not_seq  \n",
       "user_id                                                      \n",
       "0          [0, 1, 2, 1, 3, 1]    [0, 0, 0]              [0]  \n",
       "1          [4, 1, 0, 5, 6, 5]    [0, 0, 0]              [0]  \n",
       "2          [2, 0, 2, 3, 7, 1]    [1, 1, 1]              [1]  \n",
       "3          [0, 3, 0, 0, 5, 8]    [2, 2, 2]              [2]  \n",
       "4          [7, 6, 7, 7, 5, 3]    [3, 3, 3]              [3]  \n",
       "...                       ...          ...              ...  \n",
       "6035       [6, 9, 4, 4, 8, 7]    [2, 2, 2]              [2]  \n",
       "6036       [1, 8, 6, 8, 5, 6]    [0, 0, 0]              [0]  \n",
       "6037       [6, 5, 9, 8, 7, 3]    [4, 4, 4]              [4]  \n",
       "6038       [2, 1, 9, 8, 6, 3]    [8, 8, 8]              [8]  \n",
       "6039       [4, 3, 6, 0, 1, 1]    [6, 6, 6]              [6]  \n",
       "\n",
       "[6040 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_train_dataset._sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequential_train_dataset.get_sequence(0, \"item_id_seq\")\n",
    "print(seq.shape)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequential_train_dataset.get_sequence(0, \"user_cat_not_seq\")\n",
    "print(seq.shape)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_ids = test_gt.query_ids\n",
    "test_query_ids_np = tokenizer.query_id_encoder.transform(test_query_ids)[\"user_id\"].to_numpy()\n",
    "sequential_test_dataset = tokenizer.transform(test_dataset).filter_by_query_id(test_query_ids_np)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the user and item mapping and inverse mapping as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.query_id_encoder.mapping, tokenizer.query_id_encoder.inverse_mapping)\n",
    "print(tokenizer.item_id_encoder.mapping, tokenizer.item_id_encoder.inverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=SasRecTrainingDataset(\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=10,\n",
    "    ),\n",
    "    batch_size=3,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch.features[\"item_id_seq\"])\n",
    "\n",
    "    print(batch.query_id)\n",
    "    print(batch.features[\"user_cat_not_seq\"])\n",
    "    print(batch.features[\"user_cat_list_not_seq\"])\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "### Create SASRec model instance and run the training stage using lightning\n",
    "After each epoch validation metrics are shown. You can change the list of validation metrics in ValidationMetricsCallback\n",
    "The model is determined to be the best and is saved if the metric updates its maximum during validation (see the ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "model = SasRec(\n",
    "    tensor_schema,\n",
    "    block_count=2,\n",
    "    head_count=2,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"SASRec_example\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    # if you use multiple dataloaders, then add the serial number of the dataloader to the suffix of the metric name.\n",
    "    # For example,\"recall@10/dataloader_idx_0\"\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_validation_dataset)]\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=SasRecTrainingDataset(\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_validation_dataset,\n",
    "        sequential_validation_gt,\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the best model is saved inside checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SasRec.load_from_checkpoint(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference stage\n",
    "### Prepare Dataloader and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataloader = DataLoader(\n",
    "    dataset=SasRecPredictionDataset(\n",
    "        sequential_test_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/test\", name=\"SASRec_example\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference\n",
    "You can get the recommendations in three formats: PySpark DataFrame, Pandas DataFrame, PyTorch tensors. Each of the types corresponds a callback\n",
    "You can filter the results using postprocessors strategy. For example the RemoveSeenItems postprocessor is filtering out the items that already have been seen in test dataset\n",
    "You don't need to use all three callbacks. This is shown only for example\n",
    "\n",
    "Also, you can get user embeddings, that were used to perform predictions, using `get_query_embedding` method inside SasRecModel or `QueryEmbeddingsPredictionCallback` for lightning module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = [1, 10, 20, 100]\n",
    "\n",
    "postprocessors = [RemoveSeenItems(sequential_test_dataset)]\n",
    "\n",
    "spark_prediction_callback = SparkPredictionCallback(\n",
    "    spark_session=spark_session,\n",
    "    top_k=max(TOPK),\n",
    "    query_column=\"user_id\",\n",
    "    item_column=\"item_id\",\n",
    "    rating_column=\"score\",\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "\n",
    "pandas_prediction_callback = PandasPredictionCallback(\n",
    "    top_k=max(TOPK),\n",
    "    query_column=\"user_id\",\n",
    "    item_column=\"item_id\",\n",
    "    rating_column=\"score\",\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "\n",
    "torch_prediction_callback = TorchPredictionCallback(\n",
    "    top_k=max(TOPK),\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "\n",
    "query_embeddings_callback = QueryEmbeddingsPredictionCallback()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    callbacks=[\n",
    "        spark_prediction_callback,\n",
    "        pandas_prediction_callback,\n",
    "        torch_prediction_callback,\n",
    "        query_embeddings_callback\n",
    "    ], \n",
    "    logger=csv_logger, \n",
    "    inference_mode=True\n",
    ")\n",
    "trainer.predict(best_model, dataloaders=prediction_dataloader, return_predictions=False)\n",
    "\n",
    "spark_res = spark_prediction_callback.get_result()\n",
    "pandas_res = pandas_prediction_callback.get_result()\n",
    "torch_user_ids, torch_item_ids, torch_scores = torch_prediction_callback.get_result()\n",
    "user_embeddings = query_embeddings_callback.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch_user_ids[0], torch_item_ids[0], torch_scores[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to get the recomendations in PySpark format. \n",
    "Let's get the inverse representation of labels using inverse_transform method.\n",
    "\n",
    "Note that the reverse representation can only be obtained for PySpark and Pandas formats. When working with PyTorch tensors, the reverse representation must be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = tokenizer.query_and_item_id_encoder.inverse_transform(spark_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_args = {\"query_column\": \"user_id\", \"rating_column\": \"score\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics = OfflineMetrics(\n",
    "    [Recall(TOPK), Precision(TOPK), MAP(TOPK), NDCG(TOPK), MRR(TOPK), HitRate(TOPK)], **init_args\n",
    ")(recommendations.toPandas(), raw_test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_df(result_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got 6040 x 300 user embeddings, because among all 12 batches: \n",
    "\n",
    "11 batches contains 512 samples\n",
    "\n",
    "1 batch contains 408 left samples\n",
    "\n",
    "11 * 512 + 408 == 6040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access user embeddings directly with `SasRecModel` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "core_model = SasRecModel(\n",
    "    tensor_schema,\n",
    "    num_blocks=2,\n",
    "    num_heads=2,\n",
    "    max_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout=0.5\n",
    ")\n",
    "core_model.eval()\n",
    "core_model = core_model.to(device)\n",
    "\n",
    "# Get first batch of data \n",
    "data = next(iter(prediction_dataloader))\n",
    "tensor_map, padding_mask = data.features, data.padding_mask\n",
    "\n",
    "# Ensure everything is on the same device\n",
    "padding_mask = padding_mask.to(device)\n",
    "tensor_map[\"item_id_seq\"] = tensor_map[\"item_id_seq\"].to(device)\n",
    "\n",
    "# Get user embeddings\n",
    "user_embeddings_batch = core_model.get_query_embeddings(tensor_map, padding_mask)\n",
    "user_embeddings_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_all_embeddings()` method in transformers can be used to get copies of all embeddings that are presented in model as a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = best_model.get_all_embeddings()\n",
    "all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access item embeddings from this dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings = all_embeddings[\"item_embedding\"]\n",
    "item_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item embeddings shape is (N_ITEMS, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure we got correct dimension and ensure we got the copy of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert item_embeddings.shape[0] == len(tokenizer.item_id_encoder.mapping[\"item_id\"])\n",
    "assert id(item_embeddings) != id(best_model._model.item_embedder.item_emb.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example we observe one new item id in our training data. We can easily expand our item embedder by one element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to expand item embeddings by new size `set_item_embeddings_by_size` method is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.set_item_embeddings_by_size(item_embeddings.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our new item embeddings have one extra embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = best_model.get_all_embeddings()[\"item_embedding\"].shape[0]\n",
    "old_size = item_embeddings.shape[0]\n",
    "\n",
    "assert new_size == old_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can pass our item embeddings that replace the existing ones by calling `set_item_embeddings_by_tensor`.\n",
    "\n",
    "If tensor contains new items, they will be added to item embedder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embeddings_weights = torch.rand((new_size + 1, 300))    # randint used for example only\n",
    "\n",
    "best_model.set_item_embeddings_by_tensor(new_embeddings_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment we expanded our item embeddings by one more item and replace weights by passing `new_embeddings_weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_size = new_size\n",
    "new_size = best_model.get_all_embeddings()[\"item_embedding\"].shape[0]\n",
    "\n",
    "assert new_size == old_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can append tensor for only new items with no replace for existing by calling `append_item_embeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_item_weights = torch.rand((1, 300))    # randint used for example only\n",
    "\n",
    "best_model.append_item_embeddings(new_item_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We passed one new example and its weights to item embeddings, thus expanded our vocabulary by one item again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_size = new_size\n",
    "new_size = best_model.get_all_embeddings()[\"item_embedding\"].shape[0]\n",
    "\n",
    "assert new_size == old_size + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of launching an inference for a single user without using a trainer (in order to speed up)\n",
    "An example for the production of an online script\n",
    "\n",
    "Let's assume that the user's sequence consisted of a sequence of items [1, 2, 3, 4, 5]. \n",
    "Сreate a padding mask corresponding to the sequence of items.\n",
    "\n",
    "It is important to take only the latest MAX_SEQ_LEN or less items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sequence = torch.arange(1, 5).unsqueeze(0)[:, -MAX_SEQ_LEN:]\n",
    "padding_mask = torch.ones_like(item_sequence, dtype=torch.bool)\n",
    "sequence_item_count = item_sequence.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping created tensors in the SasRecPredictionBatch entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = SasRecPredictionBatch(\n",
    "    query_id=torch.arange(0, item_sequence.shape[0], 1).long(),\n",
    "    padding_mask=padding_mask.bool(),\n",
    "    features={ITEM_FEATURE_NAME: item_sequence.long()}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run predict step of the SasRec and get scores from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    scores = best_model.predict_step(batch, 0)\n",
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting three items with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(scores, k=3).indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0857f111b041889635bea848a6a183706c3f1c18c9dafdb447caa5e8bea01452"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
